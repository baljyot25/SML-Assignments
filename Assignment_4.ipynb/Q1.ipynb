{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import math\n",
    "from typing import Counter\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "data = np.load(\"C:\\\\Users\\\\baljyot\\\\Downloads\\\\mnist.npz\")\n",
    "x_train=data['x_train']\n",
    "y_train=data['y_train']\n",
    "x_test=data['x_test']\n",
    "y_test=data['y_test']\n",
    "\n",
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "\n",
    "val_indices_0 = indices_0[:1000]\n",
    "val_indices_1 = indices_1[:1000]\n",
    "\n",
    "train_indices_0 = indices_0[1000:]\n",
    "train_indices_1 = indices_1[1000:]\n",
    "\n",
    "total_1=len(train_indices_1)\n",
    "total_n1=len(train_indices_0)\n",
    "\n",
    "train_indices = np.concatenate([train_indices_0, train_indices_1])\n",
    "\n",
    "val_indices = np.concatenate([val_indices_0, val_indices_1])\n",
    "\n",
    "np.random.shuffle(train_indices)\n",
    "# np.random.shuffle(val_indices)\n",
    "\n",
    "# Create train and val sets\n",
    "x_train = np.array(x_train[train_indices])\n",
    "y_train = np.array(y_train[train_indices])\n",
    "x_val = np.array(x_train[val_indices])\n",
    "y_val = np.array(y_train[val_indices])\n",
    "\n",
    "indices = np.where((y_test == 0) | (y_test == 1))[0]\n",
    "x_test =np.array(x_test[indices])\n",
    "y_test = np.array(y_test[indices])\n",
    "\n",
    "\n",
    "flattened=[]\n",
    "for i in range(len(x_train)):\n",
    "    flattened.append(x_train[i].flatten())\n",
    "x_train=np.array(flattened)\n",
    "flattened=[]\n",
    "for i in range(len(x_val)):\n",
    "    flattened.append(x_val[i].flatten())\n",
    "x_val=np.array(flattened)\n",
    "flattened=[]\n",
    "for i in range(len(x_test)):\n",
    "    flattened.append(x_test[i].flatten())\n",
    "x_test=np.array(flattened)\n",
    "\n",
    "\n",
    "x_train=np.transpose(x_train)\n",
    "sums=[]\n",
    "centralisedMean=np.mean(x_train,axis=1)\n",
    "centralisedData=[]\n",
    "for i in range(x_train.shape[0]):\n",
    "    l=[]\n",
    "    for j in range(x_train.shape[1]):\n",
    "        l.append(x_train[i][j]- centralisedMean[i])\n",
    "    centralisedData.append(l)\n",
    "centralisedMean=np.array(np.mean(centralisedData,axis=1))\n",
    "\n",
    "S=np.matmul( centralisedData ,np.transpose(centralisedData))/18622\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(S)\n",
    "eigenvalues = eigenvalues[::-1]\n",
    "U = np.flip(eigenvectors, axis=1)\n",
    "\n",
    "nUp=U[:,:5]\n",
    "\n",
    "x_proj=np.matmul(nUp.T,x_train-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "x_test=np.transpose(x_test)\n",
    "x_proj_test=np.matmul(nUp.T,x_test-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "x_val=np.transpose(x_val)\n",
    "x_val_proj=np.matmul(nUp.T,x_val-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "\n",
    "x_val=x_val_proj\n",
    "x_test=x_proj_test\n",
    "x_train=x_proj\n",
    "\n",
    "\n",
    "y_train = np.array(y_train).astype(np.int8)\n",
    "y_val = np.array(y_val).astype(np.int8)\n",
    "y_test = np.array(y_test).astype(np.int8)\n",
    "\n",
    "y_train[y_train == 0] = -1\n",
    "y_val[y_val == 0] = -1\n",
    "y_test[y_test == 0] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Region:\n",
    "   def __init__(self):\n",
    "      self.one=0\n",
    "      self.n_one=0\n",
    "      self.tot_weight=None\n",
    "      self.misclassified_weight=None\n",
    "      self.category=None\n",
    "\n",
    "   def classify(self):\n",
    "      if (self.one>=self.n_one): self.category=1\n",
    "      else: self.category=-1\n",
    "\n",
    "   def make_region_classify(self,one,n_one):\n",
    "      self.one=one\n",
    "      self.n_one=n_one\n",
    "      self.classify()\n",
    "\n",
    "\n",
    "   def calc_loss(self, weights, x_train, y_train):\n",
    "      self.misclassified_weight=0\n",
    "      self.tot_weight=0\n",
    "      for i in range(len(y_train)):\n",
    "         self.tot_weight+=weights[i]\n",
    "         if (y_train[i]!=self.category):\n",
    "            self.misclassified_weight+=weights[i]\n",
    "      # print(self.misclassified_weight)\n",
    "\n",
    "   def remove(self, to_remove, index, y_train, weights):\n",
    "      remove_class = y_train[index]\n",
    "      self.tot_weight -= weights[index]\n",
    "      if remove_class != self.category:\n",
    "         self.misclassified_weight -= weights[index]\n",
    "      if remove_class == 1:\n",
    "         self.one -= 1\n",
    "      else:\n",
    "         self.n_one -= 1\n",
    "      prev_cat = self.category\n",
    "      self.classify()\n",
    "      if prev_cat != self.category:\n",
    "         # print(\"category changed in removing\")\n",
    "         self.misclassified_weight = self.tot_weight - self.misclassified_weight\n",
    "   \n",
    "   def add(self, to_add, index, y_train , weights):\n",
    "      add_class=y_train[index]\n",
    "      if (add_class==1):self.one+=1\n",
    "      else: self.n_one+=1\n",
    "      prev_cat=self.category\n",
    "      self.classify()\n",
    "      if (prev_cat!=self.category):\n",
    "         # print(\"category changed in adding\")\n",
    "         self.misclassified_weight = self.tot_weight - self.misclassified_weight\n",
    "      self.tot_weight+=weights[index]\n",
    "      if (add_class!=self.category):\n",
    "          self.misclassified_weight =  self.misclassified_weight+weights[index]\n",
    "\n",
    "   def print_info(self):\n",
    "      print(\"one \",self.one,end=\"  \")\n",
    "      print(\"n_one \",self.n_one,end=\"  \")\n",
    "      print(\"class \", self.category,end=\"  \")\n",
    "\n",
    "      print(\"misclassified \",self.misclassified_weight,end=\"  \")\n",
    "      print(\"tot weight \",self.tot_weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stump:\n",
    "    def __init__(self,left,right,cut,dim,loss,alpha):\n",
    "        self.Left=left \n",
    "        self.Right=right \n",
    "        self.cut=cut \n",
    "        self.dim=dim \n",
    "        self.loss=loss \n",
    "        self.alpha=alpha \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data):\n",
    "    if (data[tree.dim]<=tree.cut):\n",
    "            return tree.Left.category\n",
    "    else:\n",
    "        return tree.Right.category\n",
    "\n",
    "    \n",
    "\n",
    "def prediction(stumps , data):\n",
    "    ans=0\n",
    "    for i in range(len(stumps)):\n",
    "        ans+=stumps[i].alpha* predict(stumps[i], data)\n",
    "\n",
    "    if (ans<0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stump 1 cut 189.85586681021402  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 2 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 3 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 4 cut 250.43837259952534  best dim  1\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 5 cut 275.66982491609406  best dim  2\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 6 cut -143.0821650054794  best dim  3\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 7 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 8 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 9 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 10 cut 479.2480004048564  best dim  1\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 11 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 12 cut 131.6304096953108  best dim  2\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 13 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 14 cut -171.12288564608428  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 15 cut 173.55860515494197  best dim  1\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 16 cut 347.9227368604984  best dim  2\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 17 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 18 cut -497.8806378359968  best dim  2\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 19 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 20 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.7522030579197 %\n",
      "stump 21 cut 248.17396799608468  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 22 cut -453.6549521399354  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 23 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 24 cut 274.99098328925277  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 25 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 26 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 27 cut 479.2480004048564  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 28 cut -529.798007743082  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 29 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 30 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 31 cut -143.0821650054794  best dim  3\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 32 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 33 cut -453.6549521399354  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 34 cut 201.61394473376788  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 35 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 36 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 37 cut 274.99098328925277  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 38 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 39 cut -453.6549521399354  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 40 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 41 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 42 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 43 cut -567.6608705301801  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 44 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 45 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 46 cut 17.604889941725723  best dim  4\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 47 cut 205.82823532623394  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 48 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 49 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 50 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 51 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 52 cut 248.17396799608468  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 53 cut 347.9227368604984  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 54 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 55 cut -396.3647075725425  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 56 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 57 cut -570.9578053317737  best dim  2\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 58 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 59 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 60 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 61 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 62 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.79915141472722 %\n",
      "stump 63 cut 274.99098328925277  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 64 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 65 cut -497.8806378359968  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 66 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 67 cut -497.8806378359968  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 68 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 69 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 70 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 71 cut -497.8806378359968  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 72 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 73 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 74 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 75 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 76 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 77 cut 371.32898875590234  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 78 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 79 cut -453.6549521399354  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 80 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 81 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 82 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 83 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 84 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 85 cut -494.8536032183812  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 86 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 87 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 88 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 89 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 90 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 91 cut 273.7053968285895  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 92 cut 17.604889941725723  best dim  4\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 93 cut -529.798007743082  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 94 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 95 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 96 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 97 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 98 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 99 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 100 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 101 cut 371.32898875590234  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 102 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 103 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 104 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 105 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 106 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 107 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 108 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 109 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 110 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 111 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 112 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 113 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 114 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 115 cut 274.80923027912417  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 116 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 117 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 118 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 119 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 120 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 121 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 122 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 123 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 124 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 125 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 126 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 127 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 128 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 129 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 130 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 131 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 132 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 133 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 134 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 135 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 136 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 137 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 138 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.90610328638498 %\n",
      "stump 139 cut 274.80923027912417  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 140 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 141 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 142 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 143 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 144 cut 495.6094207585988  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 145 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 146 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 147 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 148 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 149 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 150 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 151 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 152 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 153 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 154 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 155 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 156 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 157 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 158 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 159 cut 366.1011238835983  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 160 cut 17.604889941725723  best dim  4\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 161 cut -143.0821650054794  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 162 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 163 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 164 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 165 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 166 cut -529.798007743082  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 167 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 168 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 169 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 170 cut 88.02861977638389  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 171 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 172 cut 274.80923027912417  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 173 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 174 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 175 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 176 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 177 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 178 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 179 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 180 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 181 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 182 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 183 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 184 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 185 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 186 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 187 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 188 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 189 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 190 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 191 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 192 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 193 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 194 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 195 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 196 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 197 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 198 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 199 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 200 cut 274.80923027912417  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 201 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 202 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 203 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 204 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 205 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 206 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 207 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 208 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 209 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 210 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 211 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 212 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 213 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 214 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 215 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 216 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 217 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 218 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 219 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 220 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 221 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 222 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 223 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 224 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 225 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 226 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 227 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 228 cut 365.37794149688784  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 229 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 230 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 231 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 232 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 233 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 234 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 235 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 236 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 237 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 238 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 239 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 240 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 241 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 242 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 243 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 244 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 245 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 246 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 247 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 248 cut 204.91869386208185  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 249 cut 17.604889941725723  best dim  4\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 250 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 251 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 252 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 253 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 254 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 255 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 256 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 257 cut 450.23736703980364  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 258 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 259 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 260 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 261 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 262 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 263 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 264 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 265 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 266 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 267 cut 493.63542041975245  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 268 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 269 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 270 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 271 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 272 cut 365.37794149688784  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 273 cut 554.1297941552345  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 274 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 275 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 276 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 277 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 278 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 279 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 280 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 281 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 282 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 283 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 284 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 285 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 286 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 287 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 288 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 289 cut 407.12404494220687  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 290 cut -518.1225661113165  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 291 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 292 cut -587.7303161694941  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 293 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 294 cut -482.61536842796306  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 295 cut 636.8268391112344  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 296 cut 274.80923027912417  best dim  2\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 297 cut 177.85598930246624  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 298 cut 240.40440333078982  best dim  3\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 299 cut 732.3939513026935  best dim  1\n",
      "Total Accuracy 99.8526273505561 %\n",
      "stump 300 cut -295.9743906129745  best dim  0\n",
      "Total Accuracy 99.8526273505561 %\n"
     ]
    }
   ],
   "source": [
    "values=[]\n",
    "weights=np.array([1.0]*(x_train.shape[1]))\n",
    "num_decesion_tree=300\n",
    "stumps=[]\n",
    "minimumm=1000\n",
    "maximum_accuracy=-1\n",
    "max_num_tree=0\n",
    "for st in range(num_decesion_tree):\n",
    "    total_weight=np.sum(weights)\n",
    "    # print(\"total weight for the \", st ,\"the stump is : \", total_weight)\n",
    "    mini_loss=-1\n",
    "    best_cut=None\n",
    "    best_left=None\n",
    "    best_right=None\n",
    "    best_dimension=None\n",
    "\n",
    "    for itr in range(5):\n",
    "        #all the values are unique so no need to do np.unique() (maybe beacuse of PCA)\n",
    "        curr=x_train[itr]\n",
    "        sorted_indices = np.argsort(curr)\n",
    "        s_vals =curr[sorted_indices]\n",
    "        s_y_train = y_train[sorted_indices]\n",
    "        # s_vals=np.unique(np.array(sorted(x_train[i])))\n",
    "        cut1=(s_vals[0]+s_vals[1])/2\n",
    "        i_fr_1,i_fr_n1,j_fr_1,j_fr_n1=0,0,0,0\n",
    "        i_fr=np.where(s_vals==s_vals[0])[0]\n",
    "        if (s_y_train[0]==1): i_fr_1=1\n",
    "        else: i_fr_n1=1\n",
    "        Left=Region()\n",
    "        Left.make_region_classify(i_fr_1,i_fr_n1)\n",
    "        \n",
    "        j_fr_1=total_1-i_fr_1\n",
    "        j_fr_n1=total_n1-i_fr_n1\n",
    "        Right=Region()\n",
    "        Right.make_region_classify(j_fr_1, j_fr_n1)\n",
    "\n",
    "        Left.misclassified_weight=0\n",
    "        Left.tot_weight=weights[sorted_indices[0]]\n",
    "        Right.misclassified_weight=0\n",
    "        Right.tot_weight=0\n",
    "        for i in range(1,len(sorted_indices)):\n",
    "            Right.tot_weight+=weights[sorted_indices[i]]\n",
    "            if (y_train[sorted_indices[i]]!=Right.category):\n",
    "                Right.misclassified_weight+=weights[sorted_indices[i]]\n",
    "        new_loss=Left.misclassified_weight+Right.misclassified_weight\n",
    "\n",
    "        if (new_loss<=mini_loss or mini_loss==-1):\n",
    "            mini_loss=new_loss\n",
    "            best_cut=cut1   \n",
    "            best_left=copy.deepcopy(Left)\n",
    "            best_right=copy.deepcopy(Right)\n",
    "            best_dimension=i\n",
    "    \n",
    "        for j in range(1,len(s_vals)-1):\n",
    "            cut=(s_vals[j]+s_vals[j+1])/2\n",
    "\n",
    "            Right.remove(s_vals[j],sorted_indices[j] , y_train,weights)\n",
    "            Left.add(s_vals[j], sorted_indices[j] , y_train , weights)\n",
    "            new_loss=Left.misclassified_weight+Right.misclassified_weight\n",
    "            if (new_loss<=mini_loss or mini_loss==-1):\n",
    "                mini_loss=new_loss\n",
    "                best_cut=cut\n",
    "                best_left=copy.deepcopy(Left)\n",
    "                best_right=copy.deepcopy(Right)\n",
    "                best_dimension=itr\n",
    "    print(\"stump\",st+1,\"cut\",best_cut, \" best dim \", best_dimension)\n",
    "    # print()\n",
    "\n",
    "    loss_ratio=(total_weight-mini_loss)/mini_loss\n",
    "    alpha=np.log((total_weight-mini_loss)/mini_loss)\n",
    "    # print(\"alpha \", alpha)\n",
    "    x_train_T=x_train.T\n",
    "    dim_values = x_train_T[:, best_dimension]\n",
    "\n",
    "    left_indices = np.where(dim_values <= best_cut)[0]\n",
    "\n",
    "    right_indices = np.where(dim_values > best_cut)[0]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    misclass_left_indices = [index for index in left_indices if y_train[index] != best_left.category]\n",
    "    misclass_right_indices = [index for index in right_indices if y_train[index] != best_right.category]\n",
    "\n",
    "\n",
    "    # print(loss_ratio)\n",
    "    for index in misclass_left_indices:\n",
    "        weights[index] =(weights[index]) * loss_ratio\n",
    "        \n",
    "    for index in misclass_right_indices:\n",
    "        weights[index] =(weights[index]) * loss_ratio\n",
    "\n",
    "    tree=Stump(best_left,best_right,best_cut,best_dimension,mini_loss,alpha)\n",
    "    stumps.append(tree)\n",
    "\n",
    "    x_new=x_val.T\n",
    "    acc=[[0,0] for i in range(2) ]\n",
    "    acc={\"-1\":[0,0],\"1\":[0,0]}\n",
    "    for i in range(x_new.shape[0]):\n",
    "        acc[str(y_val[i])][1]+=1\n",
    "\n",
    "        if (prediction(stumps, x_new[i])==y_val[i]):\n",
    "            acc[str(y_val[i])][0]+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # cate=[-1,1]\n",
    "    cnt=0\n",
    "    tot=0\n",
    "    for i in acc:\n",
    "        t=acc[i]\n",
    "        tot+=((t[0]/t[1])*100)\n",
    "        # print(cate[cnt],\":\",(t[0]/t[1])*100,\"%\")\n",
    "        cnt+=1\n",
    "    minimumm=min(minimumm,tot/2)\n",
    "    \n",
    "    print(\"Total Accuracy\",tot/2,\"%\")\n",
    "    values.append(tot/2)\n",
    "    if (tot/2>maximum_accuracy):\n",
    "        maximum_accuracy=tot/2\n",
    "        max_num_tree=st\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one  22  n_one  4895  class  -1  misclassified  22.0  tot weight  4917.0\n",
      "one  5720  n_one  28  class  1  misclassified  28.0  tot weight  5748.0\n"
     ]
    }
   ],
   "source": [
    "stumps[0].Left.print_info()\n",
    "stumps[0].Right.print_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "indices = np.arange(len(values))\n",
    "plt.plot(indices, values, color='blue')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Accuracy vs. Indices')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.90610328638498"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(stumps, num,x_test,y_test ):   \n",
    "    new_stumps=stumps[:num+1]\n",
    "    x_new=x_test.T\n",
    "    acc=[[0,0] for i in range(2) ]\n",
    "    acc={\"-1\":[0,0],\"1\":[0,0]}\n",
    "    for i in range(x_new.shape[0]):\n",
    "        acc[str(y_test[i])][1]+=1\n",
    "\n",
    "        if (prediction(new_stumps, x_new[i])==y_test[i]):\n",
    "            acc[str(y_test[i])][0]+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # cate=[-1,1]\n",
    "    cnt=0\n",
    "    tot=0\n",
    "    for i in acc:\n",
    "        t=acc[i]\n",
    "        tot+=((t[0]/t[1])*100)\n",
    "        print(i,\":\",(t[0]/t[1])*100,\"%\")\n",
    "        cnt+=1\n",
    "    # minimumm=min(minimumm,tot/2)\n",
    "\n",
    "    print(\"Total Accuracy\",tot/2,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 : 99.79591836734694 %\n",
      "1 : 99.64757709251101 %\n",
      "Total Accuracy 99.72174772992898 %\n"
     ]
    }
   ],
   "source": [
    "find_accuracy(stumps, max_num_tree,x_test,y_test)\n",
    "# find_accuracy(stumps, 299,x_test,y_test)s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(misclass_left_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0314467227910222"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*loss_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
