{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import math\n",
    "from typing import Counter\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "data = np.load(\"C:\\\\Users\\\\baljyot\\\\Downloads\\\\mnist.npz\")\n",
    "x_train=data['x_train']\n",
    "y_train=data['y_train']\n",
    "x_test=data['x_test']\n",
    "y_test=data['y_test']\n",
    "\n",
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "\n",
    "val_indices_0 = indices_0[:1000]\n",
    "val_indices_1 = indices_1[:1000]\n",
    "\n",
    "train_indices_0 = indices_0[1000:]\n",
    "train_indices_1 = indices_1[1000:]\n",
    "\n",
    "total_1=len(train_indices_1)\n",
    "total_n1=len(train_indices_0)\n",
    "\n",
    "train_indices = np.concatenate([train_indices_0, train_indices_1])\n",
    "\n",
    "val_indices = np.concatenate([val_indices_0, val_indices_1])\n",
    "\n",
    "np.random.shuffle(train_indices)\n",
    "# np.random.shuffle(val_indices)\n",
    "\n",
    "# Create train and val sets\n",
    "x_train = np.array(x_train[train_indices])\n",
    "y_train = np.array(y_train[train_indices])\n",
    "x_val = np.array(x_train[val_indices])\n",
    "y_val = np.array(y_train[val_indices])\n",
    "\n",
    "indices = np.where((y_test == 0) | (y_test == 1))[0]\n",
    "x_test =np.array(x_test[indices])\n",
    "y_test = np.array(y_test[indices])\n",
    "\n",
    "\n",
    "flattened=[]\n",
    "for i in range(len(x_train)):\n",
    "    flattened.append(x_train[i].flatten())\n",
    "x_train=np.array(flattened)\n",
    "flattened=[]\n",
    "for i in range(len(x_val)):\n",
    "    flattened.append(x_val[i].flatten())\n",
    "x_val=np.array(flattened)\n",
    "flattened=[]\n",
    "for i in range(len(x_test)):\n",
    "    flattened.append(x_test[i].flatten())\n",
    "x_test=np.array(flattened)\n",
    "\n",
    "\n",
    "x_train=np.transpose(x_train)\n",
    "sums=[]\n",
    "centralisedMean=np.mean(x_train,axis=1)\n",
    "centralisedData=[]\n",
    "for i in range(x_train.shape[0]):\n",
    "    l=[]\n",
    "    for j in range(x_train.shape[1]):\n",
    "        l.append(x_train[i][j]- centralisedMean[i])\n",
    "    centralisedData.append(l)\n",
    "centralisedMean=np.array(np.mean(centralisedData,axis=1))\n",
    "\n",
    "S=np.matmul( centralisedData ,np.transpose(centralisedData))/18622\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(S)\n",
    "eigenvalues = eigenvalues[::-1]\n",
    "U = np.flip(eigenvectors, axis=1)\n",
    "\n",
    "nUp=U[:,:5]\n",
    "\n",
    "x_proj=np.matmul(nUp.T,x_train-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "x_test=np.transpose(x_test)\n",
    "x_proj_test=np.matmul(nUp.T,x_test-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "x_val=np.transpose(x_val)\n",
    "x_val_proj=np.matmul(nUp.T,x_val-x_train.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "\n",
    "x_val=x_val_proj\n",
    "x_test=x_proj_test\n",
    "x_train=x_proj\n",
    "\n",
    "\n",
    "y_train = np.array(y_train).astype(np.int8)\n",
    "y_val = np.array(y_val).astype(np.int8)\n",
    "y_test = np.array(y_test).astype(np.int8)\n",
    "\n",
    "y_train[y_train == 0] = -1\n",
    "y_val[y_val == 0] = -1\n",
    "y_test[y_test == 0] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Region:\n",
    "   def __init__(self):\n",
    "      self.one=0\n",
    "      self.n_one=0\n",
    "      self.tot_weight=None\n",
    "      self.misclassified_weight=None\n",
    "      self.category=None\n",
    "\n",
    "   def classify(self):\n",
    "      if (self.one>=self.n_one): self.category=1\n",
    "      else: self.category=-1\n",
    "\n",
    "   def make_region_classify(self,one,n_one):\n",
    "      self.one=one\n",
    "      self.n_one=n_one\n",
    "      self.classify()\n",
    "\n",
    "\n",
    "   def calc_loss(self, weights, x_train, y_train):\n",
    "      self.misclassified_weight=0\n",
    "      self.tot_weight=0\n",
    "      for i in range(len(y_train)):\n",
    "         self.tot_weight+=weights[i]\n",
    "         if (y_train[i]!=self.category):\n",
    "            self.misclassified_weight+=weights[i]\n",
    "      # print(self.misclassified_weight)\n",
    "\n",
    "   def remove(self, to_remove, index, y_train, weights):\n",
    "      remove_class = y_train[index]\n",
    "      self.tot_weight -= weights[index]\n",
    "      if remove_class != self.category:\n",
    "         self.misclassified_weight -= weights[index]\n",
    "      if remove_class == 1:\n",
    "         self.one -= 1\n",
    "      else:\n",
    "         self.n_one -= 1\n",
    "      prev_cat = self.category\n",
    "      self.classify()\n",
    "      if prev_cat != self.category:\n",
    "         # print(\"category changed in removing\")\n",
    "         self.misclassified_weight = self.tot_weight - self.misclassified_weight\n",
    "   \n",
    "   def add(self, to_add, index, y_train , weights):\n",
    "      add_class=y_train[index]\n",
    "      if (add_class==1):self.one+=1\n",
    "      else: self.n_one+=1\n",
    "      prev_cat=self.category\n",
    "      self.classify()\n",
    "      if (prev_cat!=self.category):\n",
    "         # print(\"category changed in adding\")\n",
    "         self.misclassified_weight = self.tot_weight - self.misclassified_weight\n",
    "      self.tot_weight+=weights[index]\n",
    "      if (add_class!=self.category):\n",
    "          self.misclassified_weight =  self.misclassified_weight+weights[index]\n",
    "\n",
    "   def print_info(self):\n",
    "      print(\"one \",self.one,end=\"  \")\n",
    "      print(\"n_one \",self.n_one,end=\"  \")\n",
    "      print(\"class \", self.category,end=\"  \")\n",
    "\n",
    "      print(\"misclassified \",self.misclassified_weight,end=\"  \")\n",
    "      print(\"tot weight \",self.tot_weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stump:\n",
    "    def __init__(self,left,right,cut,dim,loss,alpha):\n",
    "        self.Left=left \n",
    "        self.Right=right \n",
    "        self.cut=cut \n",
    "        self.dim=dim \n",
    "        self.loss=loss \n",
    "        self.alpha=alpha \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data):\n",
    "    if (data[tree.dim]<=tree.cut):\n",
    "            return tree.Left.category\n",
    "    else:\n",
    "        return tree.Right.category\n",
    "\n",
    "    \n",
    "\n",
    "def prediction(stumps , data):\n",
    "    ans=0\n",
    "    for i in range(len(stumps)):\n",
    "        ans+=stumps[i].alpha* predict(stumps[i], data)\n",
    "\n",
    "    if (ans<0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stump 1 cut 189.85586681021374  best dim  0 alpha  5.35800036870921\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 2 cut 636.8268391112335  best dim  0 alpha  1.1741299973491786\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 3 cut -295.97439061297473  best dim  0 alpha  1.4412617754584416\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 4 cut 250.4383725995246  best dim  1 alpha  1.2143788233564503\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 5 cut 275.66982491609247  best dim  2 alpha  1.1437194671078446\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 6 cut -143.08216500547894  best dim  3 alpha  0.6839166778160989\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 7 cut -295.97439061297473  best dim  0 alpha  0.8498295877578189\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 8 cut 636.8268391112335  best dim  0 alpha  0.9593531888549192\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 9 cut -295.97439061297473  best dim  0 alpha  0.6376181577473369\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 10 cut 479.24800040485445  best dim  1 alpha  0.8334081488406353\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 11 cut -295.97439061297473  best dim  0 alpha  0.5720337451916845\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 12 cut 131.63040969530925  best dim  2 alpha  0.46241196319925715\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 13 cut 554.1297941552336  best dim  1 alpha  0.5039092701190259\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 14 cut -171.12288564608448  best dim  0 alpha  0.4414876109732432\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 15 cut 173.55860515494155  best dim  1 alpha  0.41883111309075727\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 16 cut 347.92273686049896  best dim  2 alpha  0.35201168441835945\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 17 cut 636.8268391112335  best dim  0 alpha  0.3593859489930175\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 18 cut -497.8806378359973  best dim  2 alpha  0.43219760556681847\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 19 cut 636.8268391112335  best dim  0 alpha  0.3545880472786553\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 20 cut -295.97439061297473  best dim  0 alpha  0.3282421997095976\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 21 cut 248.17396799608434  best dim  1 alpha  0.32480885767544515\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 22 cut -453.6549521399346  best dim  2 alpha  0.2543053629626705\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 23 cut 636.8268391112335  best dim  0 alpha  0.2952981463027664\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 24 cut 274.9909832892522  best dim  2 alpha  0.29413693329596613\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 25 cut 554.1297941552336  best dim  1 alpha  0.2098108647127859\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 26 cut -295.97439061297473  best dim  0 alpha  0.29513104199743323\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 27 cut 479.24800040485445  best dim  1 alpha  0.2560027658360763\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 28 cut -529.7980077430818  best dim  2 alpha  0.2374931431594567\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 29 cut 636.8268391112335  best dim  0 alpha  0.25863630370078344\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 30 cut 88.02861977638435  best dim  3 alpha  0.23153208006567513\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 31 cut -143.08216500547894  best dim  3 alpha  0.25878157992863793\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 32 cut 636.8268391112335  best dim  0 alpha  0.11995628277617354\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 33 cut -453.6549521399346  best dim  2 alpha  0.22648680558716616\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 34 cut 201.61394473376728  best dim  1 alpha  0.21150983564223172\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 35 cut -295.97439061297473  best dim  0 alpha  0.1725442500696167\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 36 cut 636.8268391112335  best dim  0 alpha  0.21180786868133716\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 37 cut 274.9909832892522  best dim  2 alpha  0.20759414693248496\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 38 cut 554.1297941552336  best dim  1 alpha  0.15004502215264925\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 39 cut -453.6549521399346  best dim  2 alpha  0.21116556205798528\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 40 cut 636.8268391112335  best dim  0 alpha  0.19501355234169862\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 41 cut 88.02861977638435  best dim  3 alpha  0.19237331155837303\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 42 cut 450.2373670398025  best dim  1 alpha  0.17811131402493602\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 43 cut -567.6608705301799  best dim  2 alpha  0.1675612314085865\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 44 cut 636.8268391112335  best dim  0 alpha  0.17500936742254958\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 45 cut -295.97439061297473  best dim  0 alpha  0.16690450900122009\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 46 cut 17.604889941724988  best dim  4 alpha  0.1581758719316732\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 47 cut 205.82823532623195  best dim  2 alpha  0.10834142140272505\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 48 cut 554.1297941552336  best dim  1 alpha  0.12242046081965077\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 49 cut -518.1225661113161  best dim  2 alpha  0.15674631273566156\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 50 cut 636.8268391112335  best dim  0 alpha  0.15098895707427187\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 51 cut -295.97439061297473  best dim  0 alpha  0.14718336228127413\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 52 cut 248.17396799608434  best dim  1 alpha  0.15398858230362517\n",
      "Total Accuracy 99.69247945094078 %\n",
      "stump 53 cut 347.92273686049896  best dim  2 alpha  0.13637398176777407\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 54 cut 636.8268391112335  best dim  0 alpha  0.12677070441948612\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 55 cut -396.364707572542  best dim  2 alpha  0.15075806186735927\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 56 cut 450.2373670398025  best dim  1 alpha  0.13867099451759105\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 57 cut -570.957805331774  best dim  2 alpha  0.1304875106080709\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 58 cut 636.8268391112335  best dim  0 alpha  0.13592340583815182\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 59 cut -295.97439061297473  best dim  0 alpha  0.13233432970477482\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 60 cut 636.8268391112335  best dim  0 alpha  0.12411101019812656\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 61 cut 88.02861977638435  best dim  3 alpha  0.12418823759393575\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 62 cut 554.1297941552336  best dim  1 alpha  0.12071852289577113\n",
      "Total Accuracy 99.74584124389702 %\n",
      "stump 63 cut 274.9909832892522  best dim  2 alpha  0.1199806218925689\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 64 cut 177.85598930246547  best dim  1 alpha  0.09893846075311398\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 65 cut -497.8806378359973  best dim  2 alpha  0.11915457736035065\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 66 cut 636.8268391112335  best dim  0 alpha  0.12634504132389926\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 67 cut -497.8806378359973  best dim  2 alpha  0.11882892227012014\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 68 cut 636.8268391112335  best dim  0 alpha  0.11215772705359411\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 69 cut -295.97439061297473  best dim  0 alpha  0.11156698672103724\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 70 cut 450.2373670398025  best dim  1 alpha  0.11325672769510504\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 71 cut -497.8806378359973  best dim  2 alpha  0.10493746244200174\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 72 cut 636.8268391112335  best dim  0 alpha  0.10309623358214073\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 73 cut -587.730316169494  best dim  3 alpha  0.10678774156643102\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 74 cut 636.8268391112335  best dim  0 alpha  0.10137030425831274\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 75 cut 88.02861977638435  best dim  3 alpha  0.10040219862984796\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 76 cut 177.85598930246547  best dim  1 alpha  0.09962577623371574\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 77 cut 371.32898875590183  best dim  2 alpha  0.0896392686831738\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 78 cut 636.8268391112335  best dim  0 alpha  0.0902341391727046\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 79 cut -453.6549521399346  best dim  2 alpha  0.10253666626239866\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 80 cut 554.1297941552336  best dim  1 alpha  0.09792703372605628\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 81 cut -295.97439061297473  best dim  0 alpha  0.09659426167744976\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 82 cut 636.8268391112335  best dim  0 alpha  0.09728372115485978\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 83 cut -587.730316169494  best dim  3 alpha  0.09895371642965604\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 84 cut 636.8268391112335  best dim  0 alpha  0.09428515511764358\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 85 cut -494.8536032183796  best dim  2 alpha  0.0919748711607968\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 86 cut 450.2373670398025  best dim  1 alpha  0.08974845840172474\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 87 cut -295.97439061297473  best dim  0 alpha  0.08592109245131146\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 88 cut 636.8268391112335  best dim  0 alpha  0.08778264026792279\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 89 cut -587.730316169494  best dim  3 alpha  0.08881100752230771\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 90 cut 732.3939513026911  best dim  1 alpha  0.08524468396840257\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 91 cut 273.7053968285893  best dim  2 alpha  0.08850288079533501\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 92 cut 17.604889941724988  best dim  4 alpha  0.08905049397565905\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 93 cut -529.7980077430818  best dim  2 alpha  0.06634447747198936\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 94 cut 177.85598930246547  best dim  1 alpha  0.08555918810103187\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 95 cut -295.97439061297473  best dim  0 alpha  0.07235111166056636\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 96 cut 636.8268391112335  best dim  0 alpha  0.08667560706069445\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 97 cut -587.730316169494  best dim  3 alpha  0.08596069956159397\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 98 cut 636.8268391112335  best dim  0 alpha  0.08241632528569375\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 99 cut -482.6153684279632  best dim  2 alpha  0.08483125716768708\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 100 cut 732.3939513026911  best dim  1 alpha  0.0818806641449577\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 101 cut 371.32898875590183  best dim  2 alpha  0.08238585034991044\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 102 cut 450.2373670398025  best dim  1 alpha  0.07145489246617462\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 103 cut -518.1225661113161  best dim  2 alpha  0.07898015297569898\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 104 cut 636.8268391112335  best dim  0 alpha  0.08029961632507257\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 105 cut 88.02861977638435  best dim  3 alpha  0.07994093415334766\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 106 cut 636.8268391112335  best dim  0 alpha  0.07498477683963821\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 107 cut -587.730316169494  best dim  3 alpha  0.07894123144127514\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 108 cut 732.3939513026911  best dim  1 alpha  0.0765796638662022\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 109 cut -295.97439061297473  best dim  0 alpha  0.07556407165457638\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 110 cut 554.1297941552336  best dim  1 alpha  0.07429135036704003\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 111 cut -518.1225661113161  best dim  2 alpha  0.07241199532659229\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 112 cut 636.8268391112335  best dim  0 alpha  0.07275068340374496\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 113 cut -587.730316169494  best dim  3 alpha  0.07340126330410356\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 114 cut 177.85598930246547  best dim  1 alpha  0.07222199770530452\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 115 cut 274.8092302791231  best dim  2 alpha  0.06729088424901873\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 116 cut 636.8268391112335  best dim  0 alpha  0.06326563962527483\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 117 cut -482.6153684279632  best dim  2 alpha  0.07502467219765256\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 118 cut 636.8268391112335  best dim  0 alpha  0.07231089505544873\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 119 cut -587.730316169494  best dim  3 alpha  0.07131414355906171\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 120 cut 636.8268391112335  best dim  0 alpha  0.06885786870248826\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 121 cut -295.97439061297473  best dim  0 alpha  0.07007866473307924\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 122 cut 450.2373670398025  best dim  1 alpha  0.06904936329351061\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 123 cut -482.6153684279632  best dim  2 alpha  0.0675256226701359\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 124 cut 636.8268391112335  best dim  0 alpha  0.06847305892756884\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 125 cut 88.02861977638435  best dim  3 alpha  0.06647514868823697\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 126 cut 732.3939513026911  best dim  1 alpha  0.06258773366875146\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 127 cut -587.730316169494  best dim  3 alpha  0.06542052807983949\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 128 cut 177.85598930246547  best dim  1 alpha  0.06468632954182048\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 129 cut -482.6153684279632  best dim  2 alpha  0.05793033004695185\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 130 cut 636.8268391112335  best dim  0 alpha  0.06707141453989511\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 131 cut -295.97439061297473  best dim  0 alpha  0.0661313041866962\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 132 cut 636.8268391112335  best dim  0 alpha  0.0640138961529222\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 133 cut -587.730316169494  best dim  3 alpha  0.06394577500633117\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 134 cut 636.8268391112335  best dim  0 alpha  0.061963954212675525\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 135 cut -482.6153684279632  best dim  2 alpha  0.06272794601175888\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 136 cut 636.8268391112335  best dim  0 alpha  0.060819789248328295\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 137 cut -587.730316169494  best dim  3 alpha  0.05989089196047588\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 138 cut 732.3939513026911  best dim  1 alpha  0.05853894121703225\n",
      "Total Accuracy 99.85256482980952 %\n",
      "stump 139 cut 274.8092302791231  best dim  2 alpha  0.060283563399878747\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 140 cut 177.85598930246547  best dim  1 alpha  0.05122163203423711\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 141 cut -518.1225661113161  best dim  2 alpha  0.057938712416479035\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 142 cut 636.8268391112335  best dim  0 alpha  0.0606396233019048\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 143 cut -295.97439061297473  best dim  0 alpha  0.06015317202901519\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 144 cut 495.60942075859725  best dim  1 alpha  0.05963151099454478\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 145 cut -482.6153684279632  best dim  2 alpha  0.05783359667809023\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 146 cut 636.8268391112335  best dim  0 alpha  0.058035875927407866\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 147 cut -587.730316169494  best dim  3 alpha  0.05847390755093651\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 148 cut 636.8268391112335  best dim  0 alpha  0.05681242541174354\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 149 cut 88.02861977638435  best dim  3 alpha  0.05668117741440371\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 150 cut 554.1297941552336  best dim  1 alpha  0.05369197399296765\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 151 cut -518.1225661113161  best dim  2 alpha  0.05490906239052498\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 152 cut 636.8268391112335  best dim  0 alpha  0.0552990769265631\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 153 cut -295.97439061297473  best dim  0 alpha  0.055337439001875106\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 154 cut 450.2373670398025  best dim  1 alpha  0.05396639041373805\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 155 cut -587.730316169494  best dim  3 alpha  0.052354155561193584\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 156 cut 636.8268391112335  best dim  0 alpha  0.053711661037568866\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 157 cut -482.6153684279632  best dim  2 alpha  0.05453350250355722\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 158 cut 636.8268391112335  best dim  0 alpha  0.053085679261478495\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 159 cut 366.1011238835982  best dim  2 alpha  0.05304334191254519\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 160 cut 17.604889941724988  best dim  4 alpha  0.04880234011258319\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 161 cut -143.08216500547894  best dim  3 alpha  0.041158039737791474\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 162 cut -295.97439061297473  best dim  0 alpha  0.048694841172512035\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 163 cut 732.3939513026911  best dim  1 alpha  0.053304219842176315\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 164 cut -295.97439061297473  best dim  0 alpha  0.05192011992778141\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 165 cut 450.2373670398025  best dim  1 alpha  0.05106630010897037\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 166 cut -529.7980077430818  best dim  2 alpha  0.050468480953248504\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 167 cut 636.8268391112335  best dim  0 alpha  0.051308867735134114\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 168 cut -587.730316169494  best dim  3 alpha  0.05119952571287282\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 169 cut 636.8268391112335  best dim  0 alpha  0.04992128054381681\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 170 cut 88.02861977638435  best dim  3 alpha  0.050329802581331885\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 171 cut 177.85598930246547  best dim  1 alpha  0.04938954609138061\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 172 cut 274.8092302791231  best dim  2 alpha  0.04845037353687837\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 173 cut 732.3939513026911  best dim  1 alpha  0.044020830551672795\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 174 cut -482.6153684279632  best dim  2 alpha  0.05135176694186782\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 175 cut 636.8268391112335  best dim  0 alpha  0.050432847183740165\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 176 cut -587.730316169494  best dim  3 alpha  0.05038611306484403\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 177 cut 636.8268391112335  best dim  0 alpha  0.04914767731577429\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 178 cut -482.6153684279632  best dim  2 alpha  0.049091564194206995\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 179 cut 554.1297941552336  best dim  1 alpha  0.048146193461154764\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 180 cut -295.97439061297473  best dim  0 alpha  0.04783514570520166\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 181 cut 636.8268391112335  best dim  0 alpha  0.04810880027512257\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 182 cut -587.730316169494  best dim  3 alpha  0.04775790836648282\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 183 cut 636.8268391112335  best dim  0 alpha  0.04664389417785034\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 184 cut -518.1225661113161  best dim  2 alpha  0.04696611433804787\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 185 cut 177.85598930246547  best dim  1 alpha  0.04703970536451302\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 186 cut -295.97439061297473  best dim  0 alpha  0.04152480278893491\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 187 cut 636.8268391112335  best dim  0 alpha  0.046667468891435415\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 188 cut -587.730316169494  best dim  3 alpha  0.046739712229685086\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 189 cut 636.8268391112335  best dim  0 alpha  0.0456721702944894\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 190 cut 240.4044033307892  best dim  3 alpha  0.04645693846544929\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 191 cut 732.3939513026911  best dim  1 alpha  0.045626173923429755\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 192 cut -482.6153684279632  best dim  2 alpha  0.045787590736512764\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 193 cut 636.8268391112335  best dim  0 alpha  0.04485786910717031\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 194 cut -587.730316169494  best dim  3 alpha  0.044615948358601575\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 195 cut 636.8268391112335  best dim  0 alpha  0.043642220839687294\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 196 cut 240.4044033307892  best dim  3 alpha  0.04414758791158305\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 197 cut 732.3939513026911  best dim  1 alpha  0.04339943647707436\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 198 cut -482.6153684279632  best dim  2 alpha  0.043649666387881016\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 199 cut 450.2373670398025  best dim  1 alpha  0.043693709010250055\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 200 cut 274.8092302791231  best dim  2 alpha  0.04367686010039328\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 201 cut 177.85598930246547  best dim  1 alpha  0.035615307857005014\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 202 cut -295.97439061297473  best dim  0 alpha  0.039823293415099825\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 203 cut 636.8268391112335  best dim  0 alpha  0.04420674640687312\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 204 cut -518.1225661113161  best dim  2 alpha  0.04421544445330364\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 205 cut 636.8268391112335  best dim  0 alpha  0.043258935477768524\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 206 cut -587.730316169494  best dim  3 alpha  0.043639624758642435\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 207 cut 636.8268391112335  best dim  0 alpha  0.04270760802446709\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 208 cut 240.4044033307892  best dim  3 alpha  0.04260467120977887\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 209 cut 732.3939513026911  best dim  1 alpha  0.04172241842919011\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 210 cut -482.6153684279632  best dim  2 alpha  0.04201020262036273\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 211 cut 636.8268391112335  best dim  0 alpha  0.04138771886180302\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 212 cut -587.730316169494  best dim  3 alpha  0.04178863080264127\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 213 cut 450.2373670398025  best dim  1 alpha  0.041090415736093636\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 214 cut -295.97439061297473  best dim  0 alpha  0.040290512063977414\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 215 cut 636.8268391112335  best dim  0 alpha  0.041058105931886996\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 216 cut -482.6153684279632  best dim  2 alpha  0.041114964451224\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 217 cut 636.8268391112335  best dim  0 alpha  0.04028665787461588\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 218 cut 240.4044033307892  best dim  3 alpha  0.04032323273149144\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 219 cut 636.8268391112335  best dim  0 alpha  0.039475512750168494\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 220 cut -587.730316169494  best dim  3 alpha  0.03980360701879901\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 221 cut 177.85598930246547  best dim  1 alpha  0.03923991926992941\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 222 cut -482.6153684279632  best dim  2 alpha  0.035418540463242186\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 223 cut 636.8268391112335  best dim  0 alpha  0.040167718633571145\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 224 cut -295.97439061297473  best dim  0 alpha  0.03956257012202792\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 225 cut 636.8268391112335  best dim  0 alpha  0.03879505590268018\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 226 cut -587.730316169494  best dim  3 alpha  0.0391351972863763\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 227 cut 732.3939513026911  best dim  1 alpha  0.03851988379929256\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 228 cut 365.37794149688705  best dim  2 alpha  0.038898488983372614\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 229 cut 554.1297941552336  best dim  1 alpha  0.034446641390336395\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 230 cut -518.1225661113161  best dim  2 alpha  0.038945088210824576\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 231 cut 636.8268391112335  best dim  0 alpha  0.038872731782415876\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 232 cut 240.4044033307892  best dim  3 alpha  0.038910013370951846\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 233 cut 636.8268391112335  best dim  0 alpha  0.038116388478762746\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 234 cut -482.6153684279632  best dim  2 alpha  0.03803031524368526\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 235 cut 450.2373670398025  best dim  1 alpha  0.03776077946287613\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 236 cut -587.730316169494  best dim  3 alpha  0.036827321540053526\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 237 cut 636.8268391112335  best dim  0 alpha  0.037184274331083476\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 238 cut -518.1225661113161  best dim  2 alpha  0.037679969905660034\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 239 cut 636.8268391112335  best dim  0 alpha  0.036983127424958\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 240 cut 240.4044033307892  best dim  3 alpha  0.03726210838327087\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 241 cut 732.3939513026911  best dim  1 alpha  0.03654417770428695\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 242 cut -295.97439061297473  best dim  0 alpha  0.03660926797270069\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 243 cut 636.8268391112335  best dim  0 alpha  0.036154546745488146\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 244 cut -587.730316169494  best dim  3 alpha  0.03624971475138155\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 245 cut 636.8268391112335  best dim  0 alpha  0.03560432208165053\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 246 cut -482.6153684279632  best dim  2 alpha  0.03576535581938817\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 247 cut 177.85598930246547  best dim  1 alpha  0.036198389758920015\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 248 cut 204.91869386208197  best dim  2 alpha  0.035504358061007615\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 249 cut 17.604889941724988  best dim  4 alpha  0.02765046585755988\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 250 cut -295.97439061297473  best dim  0 alpha  0.03400411619392026\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 251 cut 732.3939513026911  best dim  1 alpha  0.03600977009627119\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 252 cut 240.4044033307892  best dim  3 alpha  0.03596739940678561\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 253 cut 636.8268391112335  best dim  0 alpha  0.03548481523653848\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 254 cut -587.730316169494  best dim  3 alpha  0.03602386002674076\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 255 cut 636.8268391112335  best dim  0 alpha  0.035386414690384026\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 256 cut -482.6153684279632  best dim  2 alpha  0.03561813575996358\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 257 cut 450.2373670398025  best dim  1 alpha  0.03533864869765629\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 258 cut -518.1225661113161  best dim  2 alpha  0.03439310802408664\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 259 cut 636.8268391112335  best dim  0 alpha  0.034760042959265915\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 260 cut -587.730316169494  best dim  3 alpha  0.03487107681586958\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 261 cut 636.8268391112335  best dim  0 alpha  0.034273441393614476\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 262 cut 240.4044033307892  best dim  3 alpha  0.034613392354356835\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 263 cut 636.8268391112335  best dim  0 alpha  0.03397518278939207\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 264 cut -295.97439061297473  best dim  0 alpha  0.03423589331964982\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 265 cut 732.3939513026911  best dim  1 alpha  0.033831751113862725\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 266 cut -482.6153684279632  best dim  2 alpha  0.03370126392032384\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 267 cut 493.6354204197514  best dim  1 alpha  0.033608220596487236\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 268 cut -587.730316169494  best dim  3 alpha  0.033032008880395834\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 269 cut 636.8268391112335  best dim  0 alpha  0.03309964766112627\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 270 cut -482.6153684279632  best dim  2 alpha  0.03337317854028048\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 271 cut 636.8268391112335  best dim  0 alpha  0.032825384820599296\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 272 cut 365.37794149688705  best dim  2 alpha  0.03330384139332535\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 273 cut 554.1297941552336  best dim  1 alpha  0.029648767872740317\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 274 cut -295.97439061297473  best dim  0 alpha  0.032985599172581336\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 275 cut 636.8268391112335  best dim  0 alpha  0.032782514646510864\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 276 cut 240.4044033307892  best dim  3 alpha  0.03283359232825862\n",
      "Total Accuracy 99.79920303685327 %\n",
      "stump 277 cut 177.85598930246547  best dim  1 alpha  0.032564561855586066\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 278 cut -482.6153684279632  best dim  2 alpha  0.029407584278739535\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 279 cut 636.8268391112335  best dim  0 alpha  0.032991153679215166\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 280 cut -587.730316169494  best dim  3 alpha  0.03310084510343702\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 281 cut 636.8268391112335  best dim  0 alpha  0.032561883761824235\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 282 cut -482.6153684279632  best dim  2 alpha  0.03243679481270712\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 283 cut 636.8268391112335  best dim  0 alpha  0.03191907392078687\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 284 cut 240.4044033307892  best dim  3 alpha  0.03222101097991192\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 285 cut 732.3939513026911  best dim  1 alpha  0.031711078034420095\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 286 cut -587.730316169494  best dim  3 alpha  0.031931078777004296\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 287 cut 636.8268391112335  best dim  0 alpha  0.03153373724009291\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 288 cut -295.97439061297473  best dim  0 alpha  0.031656806088427\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 289 cut 407.12404494220664  best dim  1 alpha  0.03118651203506532\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 290 cut -518.1225661113161  best dim  2 alpha  0.03077541555146612\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 291 cut 636.8268391112335  best dim  0 alpha  0.031408300747146414\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 292 cut -587.730316169494  best dim  3 alpha  0.030986811329548215\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 293 cut 636.8268391112335  best dim  0 alpha  0.0305140081701382\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 294 cut -482.6153684279632  best dim  2 alpha  0.03090877305334183\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 295 cut 636.8268391112335  best dim  0 alpha  0.030438330448086973\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 296 cut 274.8092302791231  best dim  2 alpha  0.03095536231577448\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 297 cut 177.85598930246547  best dim  1 alpha  0.026006681807485773\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 298 cut 240.4044033307892  best dim  3 alpha  0.0291206563138401\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 299 cut 732.3939513026911  best dim  1 alpha  0.030933887532479422\n",
      "Total Accuracy 99.84623972547038 %\n",
      "stump 300 cut -295.97439061297473  best dim  0 alpha  0.03096240196841888\n",
      "Total Accuracy 99.84623972547038 %\n"
     ]
    }
   ],
   "source": [
    "values=[]\n",
    "weights=np.array([1.0]*(x_train.shape[1]))\n",
    "num_decesion_tree=300\n",
    "stumps=[]\n",
    "minimumm=1000\n",
    "maximum_accuracy=-1\n",
    "max_num_tree=0\n",
    "for st in range(num_decesion_tree):\n",
    "    total_weight=np.sum(weights)\n",
    "    # print(\"total weight for the \", st ,\"the stump is : \", total_weight)\n",
    "    mini_loss=-1\n",
    "    best_cut=None   \n",
    "    best_left=None\n",
    "    best_right=None\n",
    "    best_dimension=None\n",
    "\n",
    "    for itr in range(5):\n",
    "        #all the values are unique so no need to do np.unique() (maybe beacuse of PCA)\n",
    "        curr=x_train[itr]\n",
    "        sorted_indices = np.argsort(curr)\n",
    "        s_vals =curr[sorted_indices]\n",
    "        s_y_train = y_train[sorted_indices]\n",
    "        # s_vals=np.unique(np.array(sorted(x_train[i])))\n",
    "        cut1=(s_vals[0]+s_vals[1])/2\n",
    "        i_fr_1,i_fr_n1,j_fr_1,j_fr_n1=0,0,0,0\n",
    "        i_fr=np.where(s_vals==s_vals[0])[0]\n",
    "        if (s_y_train[0]==1): i_fr_1=1\n",
    "        else: i_fr_n1=1\n",
    "        Left=Region()\n",
    "        Left.make_region_classify(i_fr_1,i_fr_n1)\n",
    "        \n",
    "        j_fr_1=total_1-i_fr_1\n",
    "        j_fr_n1=total_n1-i_fr_n1\n",
    "        Right=Region()\n",
    "        Right.make_region_classify(j_fr_1, j_fr_n1)\n",
    "\n",
    "        Left.misclassified_weight=0\n",
    "        Left.tot_weight=weights[sorted_indices[0]]\n",
    "        Right.misclassified_weight=0\n",
    "        Right.tot_weight=0\n",
    "        for i in range(1,len(sorted_indices)):\n",
    "            Right.tot_weight+=weights[sorted_indices[i]]\n",
    "            if (y_train[sorted_indices[i]]!=Right.category):\n",
    "                Right.misclassified_weight+=weights[sorted_indices[i]]\n",
    "        new_loss=Left.misclassified_weight+Right.misclassified_weight\n",
    "\n",
    "        if (new_loss<=mini_loss or mini_loss==-1):\n",
    "            mini_loss=new_loss\n",
    "            best_cut=cut1   \n",
    "            best_left=copy.deepcopy(Left)\n",
    "            best_right=copy.deepcopy(Right)\n",
    "            best_dimension=i\n",
    "    \n",
    "        for j in range(1,len(s_vals)-1):\n",
    "            cut=(s_vals[j]+s_vals[j+1])/2\n",
    "\n",
    "            Right.remove(s_vals[j],sorted_indices[j] , y_train,weights)\n",
    "            Left.add(s_vals[j], sorted_indices[j] , y_train , weights)\n",
    "            new_loss=Left.misclassified_weight+Right.misclassified_weight\n",
    "            if (new_loss<=mini_loss or mini_loss==-1):\n",
    "                mini_loss=new_loss\n",
    "                best_cut=cut\n",
    "                best_left=copy.deepcopy(Left)\n",
    "                best_right=copy.deepcopy(Right)\n",
    "                best_dimension=itr\n",
    "    # print()\n",
    "\n",
    "    loss_ratio=(total_weight-mini_loss)/mini_loss\n",
    "    alpha=np.log((total_weight-mini_loss)/mini_loss)\n",
    "    print(\"stump\",st+1,\"cut\",best_cut, \" best dim \", best_dimension,\"alpha \",alpha)\n",
    "    x_train_T=x_train.T\n",
    "    dim_values = x_train_T[:, best_dimension]\n",
    "\n",
    "    left_indices = np.where(dim_values <= best_cut)[0]\n",
    "\n",
    "    right_indices = np.where(dim_values > best_cut)[0]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    misclass_left_indices = [index for index in left_indices if y_train[index] != best_left.category]\n",
    "    misclass_right_indices = [index for index in right_indices if y_train[index] != best_right.category]\n",
    "\n",
    "\n",
    "    # print(loss_ratio)\n",
    "    for index in misclass_left_indices:\n",
    "        weights[index] =(weights[index]) * loss_ratio\n",
    "        \n",
    "    for index in misclass_right_indices:\n",
    "        weights[index] =(weights[index]) * loss_ratio\n",
    "\n",
    "    tree=Stump(best_left,best_right,best_cut,best_dimension,mini_loss,alpha)\n",
    "    stumps.append(tree)\n",
    "\n",
    "    x_new=x_val.T\n",
    "    acc=[[0,0] for i in range(2) ]\n",
    "    acc={\"-1\":[0,0],\"1\":[0,0]}\n",
    "    for i in range(x_new.shape[0]):\n",
    "        acc[str(y_val[i])][1]+=1\n",
    "\n",
    "        if (prediction(stumps, x_new[i])==y_val[i]):\n",
    "            acc[str(y_val[i])][0]+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # cate=[-1,1]\n",
    "    cnt=0\n",
    "    tot=0\n",
    "    for i in acc:\n",
    "        t=acc[i]\n",
    "        tot+=((t[0]/t[1])*100)\n",
    "        # print(cate[cnt],\":\",(t[0]/t[1])*100,\"%\")\n",
    "        cnt+=1\n",
    "    minimumm=min(minimumm,tot/2)\n",
    "    \n",
    "    print(\"Total Accuracy\",tot/2,\"%\")\n",
    "    values.append(tot/2)\n",
    "    if (tot/2>maximum_accuracy):\n",
    "        maximum_accuracy=tot/2\n",
    "        max_num_tree=st\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHHCAYAAACr0swBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABgPUlEQVR4nO3de1xUZf4H8M8MDDCMgCKjDCh4IUFL3bzxE82sRrxlUiZ4SbyRa+mCsrkrJnmLaN1ddbcLubtWmxc0U9NaC6lEY73jDcoM0CIQMUsBuQ5wfn+wMzLOjM7oDGec+bxfL17OnHN4eM7XMzxfvs8zZySCIAggIiIiIj1SsTtAREREZI+YJBEREREZwSSJiIiIyAgmSURERERGMEkiIiIiMoJJEhEREZERTJKIiIiIjGCSRERERGQEkyQiIiIiI5gkERE5qC5dumDGjBm651lZWZBIJMjKyhKtT0T3EyZJRA7q7bffhkQiQXh4uNhdoTv44YcfIJFI8Je//EXsrhBRC65id4CIbGPz5s3o0qULjh07hoKCAoSEhIjdJRLZsGHDUFNTAzc3N7G7QnRfYCWJyAFdvHgRhw4dwpo1a6BUKrF582axu2RSVVWV2F1wGlKpFB4eHpBK+aufyBx8pRA5oM2bN6Ndu3YYO3Ysnn32WZNJ0vXr17Fw4UJ06dIF7u7u6NSpE2JjY3H16lXdMbW1tVi+fDl69OgBDw8PqFQqPPPMMygsLARgep2Ldgrp/fff122bMWMG2rRpg8LCQowZMwZeXl6YOnUqAODrr7/GxIkTERQUBHd3d3Tu3BkLFy5ETU2NQb+/++47REdHQ6lUQi6XIzQ0FC+//DIAYP/+/ZBIJNi1a5fB923ZsgUSiQSHDx82Go8TJ05AIpHg3//+t8G+jIwMSCQSfPrppwCAyspKLFiwQBe7Dh06YMSIETh58qTRti31/vvvQyKR4L///S8SExOhVCqhUCjw9NNP4+eff9Y7VhAEvPrqq+jUqRM8PT3x2GOP4ZtvvjFo09T/1dGjRzFmzBi0a9cOCoUCffr0wd/+9je9Y7777js8++yz8PX1hYeHBwYMGIA9e/boHaPRaLBixQo88MAD8PDwQPv27TF06FBkZmZaJSZErY3TbUQOaPPmzXjmmWfg5uaGyZMnIy0tDcePH8fAgQN1x9y4cQOPPPIIzp07h1mzZqFfv364evUq9uzZg+LiYvj5+aGxsRFPPvkkvvzyS0yaNAkJCQmorKxEZmYm8vLy0L17d4v71tDQgJEjR2Lo0KH4y1/+Ak9PTwDA9u3bUV1djRdeeAHt27fHsWPH8MYbb6C4uBjbt2/Xff/Zs2fxyCOPQCaTYc6cOejSpQsKCwvxySefICUlBcOHD0fnzp2xefNmPP300wZx6d69OwYPHmy0bwMGDEC3bt3w4YcfYvr06Xr7tm3bhnbt2mHkyJEAgLlz5+Kjjz7C/Pnz0atXL/zyyy/Izs7GuXPn0K9fP4vjYsrvfvc7tGvXDsuWLcMPP/yAdevWYf78+di2bZvumFdeeQWvvvoqxowZgzFjxuDkyZOIjIxEfX39HdvPzMzEk08+CZVKhYSEBPj7++PcuXP49NNPkZCQAAD45ptvMGTIEAQGBmLx4sVQKBT48MMPERUVhR07dujivHz5cqSmpiIuLg6DBg1CRUUFTpw4gZMnT2LEiBFWiwlRqxGIyKGcOHFCACBkZmYKgiAITU1NQqdOnYSEhAS941555RUBgLBz506DNpqamgRBEIR3331XACCsWbPG5DH79+8XAAj79+/X23/x4kUBgPDee+/ptk2fPl0AICxevNigverqaoNtqampgkQiEX788UfdtmHDhgleXl5621r2RxAEISkpSXB3dxeuX7+u23blyhXB1dVVWLZsmcHPaSkpKUmQyWTCr7/+qttWV1cntG3bVpg1a5Zum4+PjzBv3rzbtmUubaz+/Oc/67a99957AgBBrVbrndvChQsFFxcX3blduXJFcHNzE8aOHat33JIlSwQAwvTp03Xbbv2/amhoELp27SoEBwcL165d0+tTy7aeeOIJoXfv3kJtba3e/oiICOGBBx7Qbevbt68wduzYe4oFkT3hdBuRg9m8eTM6duyIxx57DAAgkUgQExODrVu3orGxUXfcjh070LdvX4Nqi/Z7tMf4+fnhd7/7nclj7sYLL7xgsE0ul+seV1VV4erVq4iIiIAgCDh16hQA4Oeff8bBgwcxa9YsBAUFmexPbGws6urq8NFHH+m2bdu2DQ0NDXjuuedu27eYmBhoNBrs3LlTt23fvn24fv06YmJidNvatm2Lo0eP4tKlS2ae9d2ZM2eO3rk98sgjaGxsxI8//ggA+OKLL1BfX4/f/e53esctWLDgjm2fOnUKFy9exIIFC9C2bVu9fdq2fv31V3z11VeIjo5GZWUlrl69iqtXr+KXX37ByJEjkZ+fj5KSEgDNMfnmm2+Qn59/j2dNZB+YJBE5kMbGRmzduhWPPfYYLl68iIKCAhQUFCA8PBxlZWX48ssvdccWFhbioYceum17hYWFCA0Nhaur9WbmXV1d0alTJ4PtRUVFmDFjBnx9fdGmTRsolUo8+uijAIDy8nIAwIULFwDgjv0OCwvDwIED9dZibd68Gf/3f/93x3f59e3bF2FhYXrTWdu2bYOfnx8ef/xx3bbVq1cjLy8PnTt3xqBBg7B8+XJd/6zp1mSwXbt2AIBr164BgC5ZeuCBB/SOUyqVumNN0a4ru108CwoKIAgCkpOToVQq9b6WLVsGALhy5QoAYOXKlbh+/Tp69OiB3r17Y9GiRTh79qy5p0pkd7gmiciBfPXVVygtLcXWrVuxdetWg/2bN29GZGSkVX+mqYpSy6pVS+7u7gbvrmpsbMSIESPw66+/4o9//CPCwsKgUChQUlKCGTNmoKmpyeJ+xcbGIiEhAcXFxairq8ORI0fw5ptvmvW9MTExSElJwdWrV+Hl5YU9e/Zg8uTJeslidHQ0HnnkEezatQv79u3Dn//8Z/zpT3/Czp07MXr0aIv7a4qLi4vR7YIgWO1n3I429i+99JJuPdattInnsGHDUFhYiN27d2Pfvn3417/+hbVr1+Kdd95BXFxcq/SXyJqYJBE5kM2bN6NDhw546623DPbt3LkTu3btwjvvvAO5XI7u3bsjLy/vtu11794dR48ehUajgUwmM3qMtlpx/fp1ve3aCoc5cnNz8f333+Pf//43YmNjddtvfVdUt27dAOCO/QaASZMmITExEenp6aipqYFMJtObLrudmJgYrFixAjt27EDHjh1RUVGBSZMmGRynUqnw4osv4sUXX8SVK1fQr18/pKSkWDVJupPg4GAAQH5+vi4+QPPUpLbaZIp24X1eXh7UarXRY7RtymQyk8e05Ovri5kzZ2LmzJm4ceMGhg0bhuXLlzNJovsSp9uIHERNTQ127tyJJ598Es8++6zB1/z581FZWal72/aECRNw5swZo2+V11YpJkyYgKtXrxqtwGiPCQ4OhouLCw4ePKi3/+233za779pqScvqiCAIBm9DVyqVGDZsGN59910UFRUZ7Y+Wn58fRo8ejU2bNmHz5s0YNWoU/Pz8zOpPz5490bt3b2zbtg3btm2DSqXCsGHDdPsbGxt1U4BaHTp0QEBAAOrq6nTbrl69iu+++w7V1dVm/dy7oVarIZPJ8MYbb+jFYN26dXf83n79+qFr165Yt26dQZKrbatDhw4YPnw41q9fj9LSUoM2Wt6O4JdfftHb16ZNG4SEhOjFhOh+wkoSkYPYs2cPKisr8dRTTxnd/3//93+6G0vGxMRg0aJF+OijjzBx4kTMmjUL/fv3x6+//oo9e/bgnXfeQd++fREbG4sPPvgAiYmJOHbsGB555BFUVVXhiy++wIsvvojx48fDx8cHEydOxBtvvAGJRILu3bvj008/1a1TMUdYWBi6d++Ol156CSUlJfD29saOHTuMVkL+/ve/Y+jQoejXrx/mzJmDrl274ocffsB//vMfnD59Wu/Y2NhYPPvsswCAVatWmR9MNFeTXnnlFXh4eGD27Nl6U4SVlZXo1KkTnn32WfTt2xdt2rTBF198gePHj+Ovf/2r7rg333wTK1aswP79+zF8+HCLfr65lEolXnrpJaSmpuLJJ5/EmDFjcOrUKXz22Wd3TAqlUinS0tIwbtw4/OY3v8HMmTOhUqnw3Xff4ZtvvkFGRgYA4K233sLQoUPRu3dvPP/88+jWrRvKyspw+PBhFBcX48yZMwCAXr16Yfjw4ejfvz98fX1x4sQJ3W0SiO5LYr2tjoisa9y4cYKHh4dQVVVl8pgZM2YIMplMuHr1qiAIgvDLL78I8+fPFwIDAwU3NzehU6dOwvTp03X7BaH5rfkvv/yy0LVrV0Emkwn+/v7Cs88+KxQWFuqO+fnnn4UJEyYInp6eQrt27YTf/va3Ql5entFbACgUCqN9+/bbbwW1Wi20adNG8PPzE55//nnhzJkzBm0IgiDk5eUJTz/9tNC2bVvBw8NDCA0NFZKTkw3arKurE9q1ayf4+PgINTU15oRRJz8/XwAgABCys7MN2l20aJHQt29fwcvLS1AoFELfvn2Ft99+W++4ZcuWGb09wq1udwuA48eP6x1r7JYLjY2NwooVKwSVSiXI5XJh+PDhQl5enhAcHHzbWwBoZWdnCyNGjNCdS58+fYQ33nhD75jCwkIhNjZW8Pf3F2QymRAYGCg8+eSTwkcffaQ75tVXXxUGDRoktG3bVpDL5UJYWJiQkpIi1NfX3/b8ieyVRBBaafUfEVEra2hoQEBAAMaNG4cNGzaI3R0ius9wTRIROayPP/4YP//8s95icCIic7GSREQO5+jRozh79ixWrVoFPz8/q32eGhE5F1aSiMjhpKWl4YUXXkCHDh3wwQcfiN0dIrpPsZJEREREZISolaTKykosWLAAwcHBkMvliIiIwPHjx3X7y8rKMGPGDAQEBMDT0xOjRo0y6zOB1q1bh9DQUMjlcnTu3BkLFy5EbW2t3jElJSV47rnn0L59e8jlcvTu3RsnTpyw+jkSERHR/UnU+yTFxcUhLy8PGzduREBAADZt2gS1Wo1vv/0WAQEBiIqKgkwmw+7du+Ht7Y01a9bo9isUCqNtbtmyBYsXL8a7776LiIgIfP/995gxYwYkEgnWrFkDoPkzj4YMGYLHHnsMn332GZRKJfLz8+/4OUdERETkPESbbqupqYGXlxd2796NsWPH6rb3798fo0ePRmxsLEJDQ5GXl4cHH3wQQPNnCPn7++O1114zeYv7+fPn49y5c3of5Pn73/8eR48eRXZ2NgBg8eLF+O9//4uvv/76rvvf1NSES5cuwcvL654+DZ2IiIhajyAIqKysREBAgMHnSN5KtEpSQ0MDGhsb4eHhobddLpcjOztb9xlLLfdLpVK4u7sjOzvbZJIUERGBTZs24dixYxg0aBAuXLiAvXv3Ytq0abpj9uzZg5EjR2LixIk4cOAAAgMD8eKLL+L555832d+6ujq9W+uXlJSgV69ed3XuREREJK6ffvoJnTp1uu0xoiVJXl5eGDx4MFatWoWePXuiY8eOSE9Px+HDhxESEoKwsDAEBQUhKSkJ69evh0KhwNq1a1FcXGz084O0pkyZgqtXr2Lo0KEQBAENDQ2YO3culixZojvmwoULSEtLQ2JiIpYsWYLjx48jPj4ebm5umD59utF2U1NTsWLFCoPt//rXv+Dp6XnvASEiIiKbq66uRlxcHLy8vO54rKjvbissLMSsWbNw8OBBuLi4oF+/fujRowdycnJw7tw55OTkYPbs2Thz5gxcXFygVqshlUohCAI+++wzo21mZWVh0qRJePXVVxEeHo6CggIkJCTg+eefR3JyMgDAzc0NAwYMwKFDh3TfFx8fj+PHj+Pw4cNG2721klRRUYHOnTvj6tWr8Pb2tmJUAI1Gg8zMTIwYMcLkJ69TM8bKMoyX+Rgr8zFWlmG8zGeLWFVUVMDPzw/l5eV3HL9FXbjdvXt3HDhwAFVVVaioqIBKpUJMTAy6desGoHl90unTp1FeXo76+noolUqEh4djwIABJttMTk7GtGnTdNNxvXv3RlVVFebMmYOXX34ZUqkUKpXKYKqsZ8+e2LFjh8l23d3d4e7ubrBdJpPZ7CK3ZduOhrGyDONlPsbKfIyVZRgv81kzVpa0Yxc3k1QoFFCpVLh27RoyMjIwfvx4vf0+Pj66d6CdOHHCYH9L1dXVBguxXFxcADQv1gKAIUOG4Pz583rHfP/99wgODrbG6RAREZEDELWSlJGRAUEQEBoaioKCAixatAhhYWGYOXMmAGD79u1QKpUICgpCbm4uEhISEBUVhcjISF0bsbGxCAwMRGpqKgBg3LhxWLNmDR5++GHddFtycjLGjRunS5YWLlyIiIgIvPbaa4iOjsaxY8fwj3/8A//4xz9aPwhERERkl0RNksrLy5GUlITi4mL4+vpiwoQJSElJ0ZXCSktLkZiYiLKyMqhUKsTGxurWFWkVFRXpVY6WLl0KiUSCpUuXoqSkBEqlEuPGjUNKSorumIEDB2LXrl1ISkrCypUr0bVrV6xbtw5Tp05tnRMnIiIiuydqkhQdHY3o6GiT++Pj4xEfH3/bNrKysvSeu7q6YtmyZVi2bNltv+/JJ5/Ek08+aXZfiYiIyLnYxZokIiIiInvDJImIiIjICCZJREREREYwSSIiIiIygkkSERERkRFMkoiIiIiMYJJEREREZISo90kisheCABQXA01NYvfEtjQa4MoVOX78EbC3j4xydQUCAgCJpPm5IAA1NYCnp3mPAaC6+uZjIqJ7xSSJCEBsLLBpk9i9aA0yAJF3PEosiYnAX//a/Hju3Ob/k3PngD/9CXjvPSAvD/jb34B//hM4cwZ45x3g7beBU6ea9//tb8CJE8BDD4l7HkTkGJgkEQE4erT5X5kM+N9H/DkoAU1NTf/7KB+J2J3RaWxsrnIdO3Zz25EjzZWhb75pflxT05wkaR/n5jb/v9XWAmfPNj+uq2t+zCSJiKyBSRIRmqdtAGD/fmDIEHH7YksaTQP27t2LMWPG6D4j0R7s3g1ERTUnS1rax42Nlj8mIrIGLtwmws21SFK+IkTh+r8/1xoabm7TPm5osPwxEZE1cEggApMksWmnOFlJIiJ7wiGBCDeTJIn9LNNxKtokiZUkIrInTJKIcHNNEitJ4tBOt7GSRET2hEMCETjdJjZjlSRtstPQYDoZ0h5/62MiImvgkEAEJkliM1ZJMpYA3TqtZiyR4nQbEVkLhwQi3Jxu45okcdxu4TYrSUQkFiZJRGAlSWy3uwUAK0lEJBYOCURgkiQ23gKAiOwRhwQiMEkSG28BQET2iB9LQgSuSRIbbwFAJD5BaP6w7+PHxe7JTaNHSzF8uHg/n0kSEVhJEtudKkmWLNxmJYno7hQVAZs2id0Lfb/5jbh/uTJJIgKTJLHdWkkShJvVPUsXbrOSRHR36uub//X0BD7/XNy+aLVt24gLF8T7+UySiMDpNrHdWkm69X5J2iSWtwAgsh3ta8jdHXjkEXH7oqXRQNQkiX83E4GVJLHdWklqOWVWV3fz8e3e9s9bABDdG+1rx5XlEx0OCURgkiS2W28B0LIa1DJJ0k4HaI9hJYnIerSvHSZJN3FIIAKTJLFpfyk3NTVPfZqqJJlKmFhJIrp3rCQZ4pBABK5JEpu2kgTorzsCTCdJLR9rNPoLvYnIckySDDFJIgIrSWJrmSS1fAcbYF6SdOu6JSKyHJMkQxwSiMAkSWwtfynfWklqOa1mzmNWkojuDpMkQ6IPCZWVlViwYAGCg4Mhl8sRERGB4y1u91lWVoYZM2YgICAAnp6eGDVqFPLz8+/Y7rp16xAaGgq5XI7OnTtj4cKFqK2tNXrs66+/DolEggULFljrtOg+o52qYZIkDlaSiMTHJMmQ6ENCXFwcMjMzsXHjRuTm5iIyMhJqtRolJSUQBAFRUVG4cOECdu/ejVOnTiE4OBhqtRpVVVUm29yyZQsWL16MZcuW4dy5c9iwYQO2bduGJUuWGBx7/PhxrF+/Hn369LHlaZId0yZIANckieV2lSRLkyRWkojuDpMkQ6ImSTU1NdixYwdWr16NYcOGISQkBMuXL0dISAjS0tKQn5+PI0eOIC0tDQMHDkRoaCjS0tJQU1OD9PR0k+0eOnQIQ4YMwZQpU9ClSxdERkZi8uTJOHbsmN5xN27cwNSpU/HPf/4T7dq1s/Xpkp3STrUBrCSJpWXcW75TDWCSRNRamCQZEjUUDQ0NaGxshIeHh952uVyO7OxsxMTEAIDefqlUCnd3d2RnZyMuLs5ouxEREdi0aROOHTuGQYMG4cKFC9i7dy+mTZumd9y8efMwduxYqNVqvPrqq7fta11dHepa/CauqKgAAGg0Gmg0GvNP2gza9qzdriOyRqyav1UGAGhs1MCRw27P15aLiysaGyWordWgpgbQ/p/U1jZB+/ecOY/r65ug0dx7pmTPsbI3jJVl7DVetbUSAK6QSq3zGrIGW8TKkrZETZK8vLwwePBgrFq1Cj179kTHjh2Rnp6Ow4cPIyQkBGFhYQgKCkJSUhLWr18PhUKBtWvXori4GKWlpSbbnTJlCq5evYqhQ4dCEAQ0NDRg7ty5etNtW7duxcmTJ/XWP91OamoqVqxYYbB937598PT0tPzkzZCZmWmTdh3RvcRKo5EAeOp/7exDmzaOv6jFHq8tieRJAC7Yt+8r1NbKADwOACgrKwfQzuzHpaVXsHfvUav1yx5jZa8YK8vYW7yOH1cBGISKimvYuzdb7O7osWasqqurzT5W9KLaxo0bMWvWLAQGBsLFxQX9+vXD5MmTkZOTA5lMhp07d2L27Nnw9fWFi4sL1Go1Ro8eDaHlQpJbZGVl4bXXXsPbb7+N8PBwFBQUICEhAatWrUJycjJ++uknJCQkIDMz06CKZUpSUhISExN1zysqKtC5c2dERkbC29v7nuPQkkajQWZmJkaMGAGZTGbVth2NNWLVcj3/qFGRsPJ/p12x52vLzU2Khgbg0Ucfx/8KtQAAubytRY/bt++AMWPG3HN/7DlW9oaxsoy9xquysnlRZocO7azyGrIGW8SqouUvmDsQPUnq3r07Dhw4gKqqKlRUVEClUiEmJgbdunUDAPTv3x+nT59GeXk56uvroVQqER4ejgEDBphsMzk5GdOmTdNNx/Xu3RtVVVWYM2cOXn75ZeTk5ODKlSvo16+f7nsaGxtx8OBBvPnmm6irq4NLy7fbAHB3d4e7u7vBz5LJZDa7yG3ZtqO5l1i1rLy6u8vgDCG3x2tL+5KTSmV6a5SaK33mP25qkkIms97iMnuMlb1irCxjb/HSvnFFJrPua8garBkrS9oRPUnSUigUUCgUuHbtGjIyMrB69Wq9/T4+PgCA/Px8nDhxAqtWrTLZVnV1NaS3rMDVJj2CIOCJJ55Abm6u3v6ZM2ciLCwMf/zjHw0SJHJsXLhtH7QvO94CgEgcXLhtSPRQZGRkQBAEhIaGoqCgAIsWLUJYWBhmzpwJANi+fTuUSiWCgoKQm5uLhIQEREVFITIyUtdGbGwsAgMDkZqaCgAYN24c1qxZg4cfflg33ZacnIxx48bBxcUFXl5eeOihh/T6oVAo0L59e4Pt5Ph4CwD7oP3FzFsAEImDSZIh0UNRXl6OpKQkFBcXw9fXFxMmTEBKSoquHFZaWorExESUlZVBpVIhNjYWycnJem0UFRXpVY6WLl0KiUSCpUuXoqSkBEqlEuPGjUNKSkqrnhvdH1hJsg+sJBGJi0mSIdFDER0djejoaJP74+PjER8ff9s2srKy9J67urpi2bJlWLZsmdn9uLUNch5MkuwDK0lE4mKSZIhDAjm9ltNtTJLE07KSxCSJqPUxSTLEIYGcXstKEtckiadlJanllJmlH3DL6Taiu8MkyRCTJHJ6TJLsg6lKkqVYSSK6O0ySDDFJIqenTZIkEiZJYjJVSbIUK0lEd0f72uFdcG5ikkROT7smiQmSuFhJIhIXK0mGmCSR09NWkrhoW1zaJImVJCJxMEkyxGGBnB6TJPtg6hYAlmIliejuaF87TJJu4rBATo9Jkn0wdTNJS7GSRHR3WEkyxGGBnB7XJNkHVpKIxMUkyRCTJHJ6rCTZBy7cJhIXkyRDHBbI6TFJsg+8BQCRuJgkGeKwQE5PO93GJElcrCQRiYtJkiEOC+T0Wt5MksTDShKRuJgkGWKSRE6P0232gZUkInExSTLEYYGcHpMk+8CbSRKJi0mSIQ4L5PR4CwD7wFsAEImLn91miEkSOT1WkuyDtabbgJv/p0RkPlaSDHFYIKfHJMk+WGvhNsApN6K7wY8lMcRhgZwebwFgH6xZSeKUG5HlWEkyxGGBnB5vAWAfWEkiEheTJENMksjpcbrNPrCSRCQuJkmGOCyQ02OSZB9YSSISF5MkQxwWyOlxTZJ9YCWJSFxMkgxxWCCnxzVJ9sFaN5MEWEkiuhtMkgwxSSKnx+k2+6D9xcxKEpE4mCQZ4rBATo9Jkn1oWUlikkTU+pgkGeKwQE6PH0tiH7hwm0hc/FgSQ0ySyOmxkmQfuHCbSFysJBnisEBOj0mSfWAliUhc/FgSQxwWyOnxFgD2gZUkInGxkmSIwwI5Pd4CwD7wFgBE4mKSZEj0JKmyshILFixAcHAw5HI5IiIicPz4cd3+srIyzJgxAwEBAfD09MSoUaOQn59/x3bXrVuH0NBQyOVydO7cGQsXLkRtba1uf2pqKgYOHAgvLy906NABUVFROH/+vE3Okewbp9vsA28BQCQuJkmGRB8W4uLikJmZiY0bNyI3NxeRkZFQq9UoKSmBIAiIiorChQsXsHv3bpw6dQrBwcFQq9Woqqoy2eaWLVuwePFiLFu2DOfOncOGDRuwbds2LFmyRHfMgQMHMG/ePBw5cgSZmZnQaDSIjIy8bbvkmJgk2QdWkojExSTJkKihqKmpwY4dO7B7924MGzYMALB8+XJ88sknSEtLQ2xsLI4cOYK8vDw8+OCDAIC0tDT4+/sjPT0dcXFxRts9dOgQhgwZgilTpgAAunTpgsmTJ+Po0aO6Yz7//HO973n//ffRoUMH5OTk6PpCzoFrkuwDK0lE4mKSZEjUUDQ0NKCxsREeHh562+VyObKzsxETEwMAevulUinc3d2RnZ1tMkmKiIjApk2bcOzYMQwaNAgXLlzA3r17MW3aNJN9KS8vBwD4+voa3V9XV4e6ujrd84qKCgCARqOBRqMx42zNp23P2u06ImvEqr5eguaXQhM0GsceXe372pICcIFG0/S/X9Z3n7XW1TVAoxHuqTf2HSv7wlhZxl7j1dDgCkACQdDAXrpmi1hZ0paoSZKXlxcGDx6MVatWoWfPnujYsSPS09Nx+PBhhISEICwsDEFBQUhKSsL69euhUCiwdu1aFBcXo7S01GS7U6ZMwdWrVzF06FAIgoCGhgbMnTtXb7qtpaamJixYsABDhgzBQw89ZPSY1NRUrFixwmD7vn374OnpeXcBuIPMzEybtOuI7iVWx4/7AwhHRcV17N37tfU6Zcfs8dr67rsuAPqipOQyampcAXS467YOHTqGqqqfrdIve4yVvWKsLGNv8aqvfxKAC77+ej+++65G7O7osWasqqurzT5W9KLaxo0bMWvWLAQGBsLFxQX9+vXD5MmTkZOTA5lMhp07d2L27Nnw9fWFi4sL1Go1Ro8eDUEw/VdiVlYWXnvtNbz99tsIDw9HQUEBEhISsGrVKiQnJxscP2/ePOTl5SE7O9tkm0lJSUhMTNQ9r6ioQOfOnREZGQlvb+97C8ItNBoNMjMzMWLECMhkMqu27WisESuNpvltbb6+bTFmzBhrds/u2PO1VVra/P/g5+ePGzfura3+/QchMvLeK0n2Git7w1hZxl7j1dTUXL0dMeIxBASI3Jn/sUWstDNB5hA9SerevTsOHDiAqqoqVFRUQKVSISYmBt26dQMA9O/fH6dPn0Z5eTnq6+uhVCoRHh6OAQMGmGwzOTkZ06ZN003H9e7dG1VVVZgzZw5efvllSFssPpk/fz4+/fRTHDx4EJ06dTLZpru7O9zd3Q22y2Qym13ktmzb0dxLrLSXg1QqhUzmHAuT7PHa0r68BEFqhTVFrrDW6dljrOwVY2UZe4qXINxcy+fhIbPa68darBkrS9qxmxFBoVBApVLh2rVryMjIwPjx4/X2+/j4QKlUIj8/HydOnDDY31J1dbVeIgQALv9764y2AiUIAubPn49du3bhq6++QteuXa18RnS/4Lvb7ANvJkkknpavGS7cvkn0UGRkZEAQBISGhqKgoACLFi1CWFgYZs6cCQDYvn07lEolgoKCkJubi4SEBERFRSEyMlLXRmxsLAIDA5GamgoAGDduHNasWYOHH35YN92WnJyMcePG6ZKlefPmYcuWLdi9eze8vLxw+fJlAM3JmFwub+UokJiYJNkH3gKASDxMkowTPRTl5eVISkpCcXExfH19MWHCBKSkpOjKYaWlpUhMTERZWRlUKhViY2MN1hUVFRXpVY6WLl0KiUSCpUuXoqSkBEqlEuPGjUNKSorumLS0NADA8OHD9dp67733MGPGDNucLNkl3gLAPvAWAETiafmHBZOkm0QPRXR0NKKjo03uj4+PR3x8/G3byMrK0nvu6uqKZcuWYdmyZSa/53YLv8m58GNJ7AMrSUTiYZJkHP92JqfH6Tb7wEoSkXiYJBnHYYGcHpMk+9CyksQkiah1tUyS+LvwJoaCnB7XJNmHlpUkTrcRta6WH0nCpQc3cVggp8c1SfbBWCWp5a3JLHnMShKRZfi5bcYxSSKnx+k2+6D95dxy4fbdJkmsJBFZhkmScRwWyOlxus0+GLuZJCtJRK2DSZJxHBbI6XG6zT4YuwUAK0lErUP7mtG+DqkZkyRyepxusw/GbgHAShJR62AlyTgOC+T0mCTZB1aSiMSj/cOCSZI+Dgvk9LgmyT6wkkQkHlaSjOOwQE6Pa5Lsg7FbALi53dxvyWMmSUSWYZJkHJMkcnqcbrMPxm4myek2otbBJMk4Dgvk9DjdZh94M0ki8TBJMo7DAjk9VpLsgzXXJLGSRGQZJknGcVggp8c1SfZBW0mqr7+5jZUkotbBJMk4Jknk9FhJsg/WTJJYSSKyDJMk4zgskNPjmiT7YOyXMytJRK2DSZJxHBbI6XG6zT4Y+ziEu70FACtJRJbhx5IYxySJnB6n2+wDK0lE4mElyTgOC+T0mCTZB2N/wTJJImodTJKM47BATo9rkuzDrb+cJRJAJrv5nAu3iWyHn91mHIcFcnpck2Qfbq0kubrqb7MkYWIlicgyrCQZxySJnB6n2+zDrb+cXVxubnN11d9/p4SJlSQiyzBJMo7DAjk9TrfZh9tVklxc9B+3/EXe8t1trCQR3R0mScZxWCCnx0qSfZBI9Kc8b02MjD2WSo0nTKwkEVmGSZJxHBbI6XFNkv1o+Qu65RSbOY+l0pvTcKwkEVmGSZJxTJLI6bGSZD9aTrmZU0ky9ZhJEpFlmCQZx2GBnB7XJNmPe6kktXzM6TYiyzBJMo7DAjk9TrfZD1aSiMTBjyUxjkkSOT1Ot9mPln/FmroFwK2Ptb/UWz5mJYnIMqwkGcdhgZwep9vsR8u/Ym93CwBjtwNo+ZiVJCLLMEkyTvRhobKyEgsWLEBwcDDkcjkiIiJw/Phx3f6ysjLMmDEDAQEB8PT0xKhRo5Cfn3/HdtetW4fQ0FDI5XJ07twZCxcuRG1trd4xb731Frp06QIPDw+Eh4fj2LFjVj8/sn+sJNkPVpKIxMGPJTFO9GEhLi4OmZmZ2LhxI3JzcxEZGQm1Wo2SkhIIgoCoqChcuHABu3fvxqlTpxAcHAy1Wo2qqiqTbW7ZsgWLFy/GsmXLcO7cOWzYsAHbtm3DkiVLdMds27YNiYmJWLZsGU6ePIm+ffti5MiRuHLlSmucNtkRrkmyH6wkEYmDlSTjRE2SampqsGPHDqxevRrDhg1DSEgIli9fjpCQEKSlpSE/Px9HjhxBWloaBg4ciNDQUKSlpaGmpgbp6ekm2z106BCGDBmCKVOmoEuXLoiMjMTkyZP1KkVr1qzB888/j5kzZ6JXr15455134OnpiXfffbc1Tp3sCCtJ9sNaC7dZSSKyDJMk40QNR0NDAxobG+Hh4aG3XS6XIzs7GzExMQCgt18qlcLd3R3Z2dmIi4sz2m5ERAQ2bdqEY8eOYdCgQbhw4QL27t2LadOmAQDq6+uRk5ODpKQkvXbVajUOHz5stM26ujrU1dXpnldUVAAANBoNNBrNXZy9adr2rN2uI7JGrBobpQBcIAiN0GiarNQz+2Tv15arqyuA5pKei4sAoBGAq1mPXV1vPm5oEKDR3FumZO+xsieMlWXsMV719c2/ByUS+/o9aItYWdKWqEmSl5cXBg8ejFWrVqFnz57o2LEj0tPTcfjwYYSEhCAsLAxBQUFISkrC+vXroVAosHbtWhQXF6O0tNRku1OmTMHVq1cxdOhQCIKAhoYGzJ07VzfddvXqVTQ2NqJjx45639exY0d89913RttMTU3FihUrDLbv27cPnp6e9xAF0zIzM23SriO6l1j98EMfAF1RWPg99u793nqdsmP2em3V1DwOwAsAcOPGdZw5kw9gEKqqynH69HkA4aiursTJk98AGIza2hvIyckFEIHa2iqcOHEGwBD88ksV3n//kBV6JMfmzdlWaMcZMFaWsa94nTvXC0AnFBaex969d17329qs+Tururra7GNFL6xt3LgRs2bNQmBgIFxcXNCvXz9MnjwZOTk5kMlk2LlzJ2bPng1fX1+4uLhArVZj9OjRELRvSTIiKysLr732Gt5++22Eh4ejoKAACQkJWLVqFZKTk++qn0lJSUhMTNQ9r6ioQOfOnREZGQlvb++7atMUjUaDzMxMjBgxArKWH3dOBqwRq08/bZ5n69GjB8aMCbFm9+yOvV9bPj6uKClpfuzr64NBg/oBANq180Z4eH8AQNu2Xhg8eCAAwNu7DSIiBgEAvLwUGDIkHABw6VIbzJkT2cq9J7r/9eoVijFjHhC7Gzq2+J2lnQkyh+hJUvfu3XHgwAFUVVWhoqICKpUKMTEx6NatGwCgf//+OH36NMrLy1FfXw+lUonw8HAMGDDAZJvJycmYNm2abjqud+/eqKqqwpw5c/Dyyy/Dz88PLi4uKCsr0/u+srIy+Pv7G23T3d0d7tqPGG9BJpPZbLCxZduOxhqxkslcIJM5x53U7PXamjQJeP315kX00dFSDB0qRVgYEBMjRUSEFD17ApMmSfB//+eKBx8EYmIkGDTIFQ89BDzzjAQDBjRvLyy0Rm8ENDU1QSqVQjsFSKYwVpaxz3j5+gKjRtnn70Fr/s6ypB3RkyQthUIBhUKBa9euISMjA6tXr9bb7+PjAwDIz8/HiRMnsGrVKpNtVVdX/+/iu8nlfys6BUGAm5sb+vfvjy+//BJRUVEAgKamJnz55ZeYP3++Fc+K7ge8T5L9SE5u/mrp3Lmbj7/99ubjvLybj3NzjW+/FxpNA/bu3YsxY8bYZUJpTxgryzBe9w/Rk6SMjAwIgoDQ0FAUFBRg0aJFCAsLw8yZMwEA27dvh1KpRFBQEHJzc5GQkICoqChERt4spcfGxiIwMBCpqakAgHHjxmHNmjV4+OGHddNtycnJGDdunC5ZSkxMxPTp0zFgwAAMGjQI69atQ1VVle7nkvPgLQCIiMgY0ZOk8vJyJCUlobi4GL6+vpgwYQJSUlJ02XVpaSkSExNRVlYGlUqF2NhYg3VFRUVFepWjpUuXQiKRYOnSpSgpKYFSqcS4ceOQkpKiOyYmJgY///wzXnnlFVy+fBm/+c1v8Pnnnxss5ibHx1sAEBGRMaInSdHR0YiOjja5Pz4+HvHx8bdtIysrS++5q6srli1bhmXLlt32++bPn8/pNeJ0GxERGcVhgZweK0lERGQMhwVyelyTRERExjBJIqfHShIRERnDYYGcHtckERGRMRwWyOlxuo2IiIxhkkROj9NtRERkDIcFcnqcbiMiImM4LJDTYyWJiIiM4bBATo9rkoiIyBgmSeT0WEkiIiJjOCyQ0+OaJCIiMobDAjk9VpKIiMgYDgvk9LgmiYiIjGGSRE6PlSQiIjKGwwI5Pa5JIiIiYzgskNPjdBsRERnDJImcHqfbiIjIGA4L5PQ43UZERMZwWCCnx0oSEREZw2GBnB7XJBERkTFMksjpsZJERETGcFggp8c1SUREZAyHBXJ6rCQREZExHBbI6XFNEhERGcMkiZwep9uIiMgYDgvk9DjdRkRExnBYIKfH6TYiIjKGSRI5PVaSiIjIGA4L5PS4JomIiIzhsEBOj5UkIiIyhsMCOT2uSSIiImNET5IqKyuxYMECBAcHQy6XIyIiAsePH9ftLysrw4wZMxAQEABPT0+MGjUK+fn5t21z+PDhkEgkBl9jx47VHXPjxg3Mnz8fnTp1glwuR69evfDOO+/Y7DzJfrGSRERExriK3YG4uDjk5eVh48aNCAgIwKZNm6BWq/Htt98iICAAUVFRkMlk2L17N7y9vbFmzRrdfoVCYbTNnTt3or6+Xvf8l19+Qd++fTFx4kTdtsTERHz11VfYtGkTunTpgn379uHFF19EQEAAnnrqKZufN9kPrkkiIiJjRB0WampqsGPHDqxevRrDhg1DSEgIli9fjpCQEKSlpSE/Px9HjhxBWloaBg4ciNDQUKSlpaGmpgbp6ekm2/X19YW/v7/uKzMzE56ennpJ0qFDhzB9+nQMHz4cXbp0wZw5c9C3b18cO3asNU6d7AgrSUREZMxdVZIaGhqQlZWFwsJCTJkyBV5eXrh06RK8vb3Rpk0bi9ppbGyEh4eH3na5XI7s7GzExMQAgN5+qVQKd3d3ZGdnIy4uzqyfs2HDBkyaNEmv8hQREYE9e/Zg1qxZCAgIQFZWFr7//nusXbvWaBt1dXWoq6vTPa+oqAAAaDQaaDQa807YTNr2rN2uI7JGrJqaXAFI0NjYAI1GsFLP7BOvLfMxVuZjrCzDeJnPFrGypC2JIAgWjQo//vgjRo0ahaKiItTV1eH7779Ht27dkJCQgLq6OovX9URERMDNzQ1btmxBx44dkZ6ejunTpyMkJAR5eXkICQlBeHg41q9fD4VCgbVr12Lx4sWIjIxERkbGHds/duwYwsPDcfToUQwaNEi3va6uDnPmzMEHH3wAV1dXSKVS/POf/0RsbKzRdpYvX44VK1YYbN+yZQs8PT0tOmeyL3PmqHHligKrVx9Ajx7Xxe4OERHZUHV1NaZMmYLy8nJ4e3vf9liLK0kJCQkYMGAAzpw5g/bt2+u2P/3003j++ect7uzGjRsxa9YsBAYGwsXFBf369cPkyZORk5MDmUyGnTt3Yvbs2fD19YWLiwvUajVGjx4Nc3O7DRs2oHfv3noJEgC88cYbOHLkCPbs2YPg4GAcPHgQ8+bNQ0BAANRqtUE7SUlJSExM1D2vqKhA586dERkZeccgW0qj0SAzMxMjRoyATCazatuOxhqx8vBofhk88sgQ9O/v+JUkXlvmYazMx1hZhvEyny1ipZ0JMofFSdLXX3+NQ4cOwc3NTW97ly5dUFJSYmlz6N69Ow4cOICqqipUVFRApVIhJiYG3bp1AwD0798fp0+fRnl5Oerr66FUKhEeHo4BAwbcse2qqips3boVK1eu1NteU1ODJUuWYNeuXbp3vPXp0wenT5/GX/7yF6NJkru7O9zd3Q22y2Qym13ktmzb0dxLrLRrkmQyVzhLuHltmY+xMh9jZRnGy3zWjJUl7Vi8VLWpqQmNjY0G24uLi+Hl5WVpczoKhQIqlQrXrl1DRkYGxo8fr7ffx8cHSqUS+fn5OHHihMF+Y7Zv3466ujo899xzetu164ikt6zUdXFxQZN2xCSnwYXbRERkjMWVpMjISKxbtw7/+Mc/AAASiQQ3btzAsmXLMGbMGIs7kJGRAUEQEBoaioKCAixatAhhYWGYOXMmgOZER6lUIigoCLm5uUhISEBUVBQiIyN1bcTGxiIwMBCpqal6bW/YsAFRUVF604IA4O3tjUcffRSLFi2CXC5HcHAwDhw4gA8++ABr1qyx+Bzo/sZbABARkTEWJ0l//etfMXLkSPTq1Qu1tbWYMmUK8vPz4efnd9u35ZtSXl6OpKQkFBcXw9fXFxMmTEBKSoquHFZaWorExESUlZVBpVIhNjYWycnJem0UFRUZVIXOnz+P7Oxs7Nu3z+jP3bp1K5KSkjB16lT8+uuvCA4ORkpKCubOnWvxOdD9jZUkIiIyxuIkqVOnTjhz5gy2bt2Ks2fP4saNG5g9ezamTp0KuVxucQeio6MRHR1tcn98fDzi4+Nv20ZWVpbBttDQ0Nsu7vb398d7771ndj/JcfFjSYiIyJi7uk+Sq6urwTofovsVp9uIiMgYi5OkDz744Lb7Td1niMhecbqNiIiMuav7JLWk0WhQXV0NNzc3eHp6Mkmi+w6TJCIiMsbiYeHatWt6Xzdu3MD58+cxdOjQu1q4TSQ2rkkiIiJjrPK38wMPPIDXX3/doMpEdD/gmiQiIjLGasOCq6srLl26ZK3miFoNp9uIiMgYi9ck7dmzR++5IAgoLS3Fm2++iSFDhlitY0SthdNtRERkjMVJUlRUlN5ziUQCpVKJxx9/HH/961+t1S+iVsNKEhERGWNxksTPNiNHwzVJRERkDIcFcnqsJBERkTFmVZISExPNbpAfEEv3G65JIiIiY8xKkk6dOmVWYxKOMnQf4nQbEREZY1aStH//flv3g0gUgsAkiYiIjOOwQE5NmyABTJKIiEifxe9uA4ATJ07gww8/RFFREerr6/X27dy50yodI2oNLd+sydliIiJqyeK/nbdu3YqIiAicO3cOu3btgkajwTfffIOvvvoKPj4+tugjkc2wkkRERKZYPCy89tprWLt2LT755BO4ubnhb3/7G7777jtER0cjKCjIFn0kspmWlSQmSURE1JLFw0JhYSHGjh0LAHBzc0NVVRUkEgkWLlyIf/zjH1bvIJEtcbqNiIhMsThJateuHSorKwEAgYGByMvLAwBcv34d1dXV1u0dkY1xuo2IiEwxe1jQJkPDhg1DZmYmAGDixIlISEjA888/j8mTJ+OJJ56wTS+JbITTbUREZIrZ727r06cPBg4ciKioKEycOBEA8PLLL0Mmk+HQoUOYMGECli5darOOEtkCkyQiIjLF7CTpwIEDeO+995CamoqUlBRMmDABcXFxWLx4sS37R2RTXJNERESmmP238yOPPIJ3330XpaWleOONN/DDDz/g0UcfRY8ePfCnP/0Jly9ftmU/iWyCa5KIiMgUi4cFhUKBmTNn4sCBA/j+++8xceJEvPXWWwgKCsJTTz1liz4S2Qyn24iIyJR7GhZCQkKwZMkSLF26FF5eXvjPf/5jrX4RtQpOtxERkSl39bEkAHDw4EG8++672LFjB6RSKaKjozF79mxr9o3I5pgkERGRKRYlSZcuXcL777+P999/HwUFBYiIiMDf//53REdHQ6FQ2KqPRDajXZPEqTYiIrqV2UnS6NGj8cUXX8DPzw+xsbGYNWsWQkNDbdk3IpvTVpKYJBER0a3MTpJkMhk++ugjPPnkk3BxcbFln4hajTZJ4lQbERHdyuwkac+ePbbsB5EoON1GRESmcGggp8bpNiIiMkX0oaGyshILFixAcHAw5HI5IiIicPz4cd3+srIyzJgxAwEBAfD09MSoUaOQn59/2zaHDx8OiURi8DV27Fi9486dO4ennnoKPj4+UCgUGDhwIIqKimxynmSfmCQREZEpog8NcXFxyMzMxMaNG5Gbm4vIyEio1WqUlJRAEARERUXhwoUL2L17N06dOoXg4GCo1WpUVVWZbHPnzp0oLS3VfeXl5cHFxUX3mXMAUFhYiKFDhyIsLAxZWVk4e/YskpOT4eHh0RqnTXaCa5KIiMiUu75PkjXU1NRgx44d2L17N4YNGwYAWL58OT755BOkpaUhNjYWR44cQV5eHh588EEAQFpaGvz9/ZGeno64uDij7fr6+uo937p1Kzw9PfWSpJdffhljxozB6tWrddu6d+9u7VMkO8c1SUREZIqoSVJDQwMaGxsNqjdyuRzZ2dmIiYkBAL39UqkU7u7uyM7ONpkk3WrDhg2YNGmS7l5OTU1N+M9//oM//OEPGDlyJE6dOoWuXbsiKSkJUVFRRtuoq6tDXV2d7nlFRQUAQKPRQKPRmH3O5tC2Z+12HdG9xqr5v1QGqVSARtNgvY7ZKV5b5mOszMdYWYbxMp8tYmVJWxJBaPkRn60vIiICbm5u2LJlCzp27Ij09HRMnz4dISEhyMvLQ0hICMLDw7F+/XooFAqsXbsWixcvRmRkJDIyMu7Y/rFjxxAeHo6jR49i0KBBAIDLly9DpVLB09MTr776Kh577DF8/vnnWLJkCfbv349HH33UoJ3ly5djxYoVBtu3bNkCT0/Pew8EiaK4uA3mz38CXl712LjxM7G7Q0RENlZdXY0pU6agvLwc3t7etz1W9CSpsLAQs2bNwsGDB+Hi4oJ+/fqhR48eyMnJwblz55CTk4PZs2fjzJkzcHFxgVqthlQqhSAI+OyzOw9qv/3tb3H48GGcPXtWt+3SpUsIDAzE5MmTsWXLFt32p556CgqFAunp6QbtGKskde7cGVevXr1jkC2l0WiQmZmJESNGQCaTWbVtR3OvsTp3DujbV4b27QWUljpHJYnXlnkYK/MxVpZhvMxni1hVVFTAz8/PrCRJ1Ok2oHkd0IEDB1BVVYWKigqoVCrExMSgW7duAID+/fvj9OnTKC8vR319PZRKJcLDwzFgwIA7tl1VVYWtW7di5cqVetv9/Pzg6uqKXr166W3v2bMnsrOzjbbl7u4Od3d3g+0ymcxmF7kt23Y0dxsr7X1RpVKJU8Wa15b5GCvzMVaWYbzMZ81YWdKO3SxXVSgUUKlUuHbtGjIyMjB+/Hi9/T4+PlAqlcjPz8eJEycM9huzfft21NXV4bnnntPb7ubmhoEDB+L8+fN627///nsEBwff+8nQfYO3ACAiIlNEryRlZGRAEASEhoaioKAAixYtQlhYGGbOnAmgOdFRKpUICgpCbm4uEhISEBUVhcjISF0bsbGxCAwMRGpqql7bGzZsQFRUFNq3b2/wcxctWoSYmBgMGzZMtybpk08+QVZWlk3Pl+wLbwFARESmiJ4klZeXIykpCcXFxfD19cWECROQkpKiK4eVlpYiMTERZWVlUKlUiI2NRXJysl4bRUVFkN5SCjh//jyys7Oxb98+oz/36aefxjvvvIPU1FTEx8cjNDQUO3bswNChQ21zomSXeAsAIiIyRfQkKTo6GtHR0Sb3x8fHIz4+/rZtGKv+hIaG4k5r0mfNmoVZs2aZ1U9yTJxuIyIiUzg0kFNjkkRERKZwaCCnxjVJRERkCpMkcmpck0RERKZwaCCnxuk2IiIyhUMDOTUmSUREZAqHBnJq2uk2rkkiIqJbMUkip8ZKEhERmcKhgZwakyQiIjKFQwM5Nd4CgIiITGGSRE6NtwAgIiJTODSQU+N0GxERmcKhgZwakyQiIjKFQwM5Nd4CgIiITGGSRE6NlSQiIjKFQwM5NSZJRERkCocGcmpMkoiIyBQODeTUuCaJiIhMYZJETo2VJCIiMoVDAzk1JklERGQKhwZyavxYEiIiMoVJEjk1fiwJERGZ4ip2B4ispakJ+Okny77nypXmf5kkERHRrZgkkcMYMwbIyLi77+V0GxER3YpJEjmMI0ea/3Vzs6wyJJMBEybYpk9ERHT/YpJEDqOxsfnfb78FuncXty9ERHT/40oMchgNDc3/ujL1JyIiK2CSRA5DW0lycRG3H0RE5BiYJJHD0FaSmCQREZE1MEkihyAIN+95xOk2IiKyBiZJ5BC0U20AK0lERGQdTJLIIWin2gBWkoiIyDpET5IqKyuxYMECBAcHQy6XIyIiAsePH9ftLysrw4wZMxAQEABPT0+MGjUK+fn5t21z+PDhkEgkBl9jx441evzcuXMhkUiwbt06a54atSJWkoiIyNpET5Li4uKQmZmJjRs3Ijc3F5GRkVCr1SgpKYEgCIiKisKFCxewe/dunDp1CsHBwVCr1aiqqjLZ5s6dO1FaWqr7ysvLg4uLCyZOnGhw7K5du3DkyBEEBATY8jTJxlhJIiIiaxM1SaqpqcGOHTuwevVqDBs2DCEhIVi+fDlCQkKQlpaG/Px8HDlyBGlpaRg4cCBCQ0ORlpaGmpoapKenm2zX19cX/v7+uq/MzEx4enoaJEklJSX43e9+h82bN0Mmk9n6dMmGWEkiIiJrE/Vv7oaGBjQ2NsLDw0Nvu1wuR3Z2NmJiYgBAb79UKoW7uzuys7MRFxdn1s/ZsGEDJk2aBIVCodvW1NSEadOmYdGiRXjwwQfv2EZdXR3q6up0zysqKgAAGo0GGo3GrH6YS9uetdt1RNoY1dRoADQnuk1NGjB0xvHaMh9jZT7GyjKMl/lsEStL2hI1SfLy8sLgwYOxatUq9OzZEx07dkR6ejoOHz6MkJAQhIWFISgoCElJSVi/fj0UCgXWrl2L4uJilJaWmvUzjh07hry8PGzYsEFv+5/+9Ce4uroiPj7erHZSU1OxYsUKg+379u2Dp6enWW1YKjMz0ybtOqL9+w8CGAWpVMBnn+0Vuzt2j9eW+Rgr8zFWlmG8zGfNWFVXV5t9rEQQtHeXEUdhYSFmzZqFgwcPwsXFBf369UOPHj2Qk5ODc+fOIScnB7Nnz8aZM2fg4uICtVoNqVQKQRDw2Wef3bH93/72tzh8+DDOnj2r25aTk4OxY8fi5MmTurVIXbp0wYIFC7BgwQKj7RirJHXu3BlXr16Ft7f3vQXhFhqNBpmZmRgxYgSnAe9AG6uePSMRGiqHTCagqqrhzt/opHhtmY+xMh9jZRnGy3y2iFVFRQX8/PxQXl5+x/Fb9CWu3bt3x4EDB1BVVYWKigqoVCrExMSgW7duAID+/fvj9OnTKC8vR319PZRKJcLDwzFgwIA7tl1VVYWtW7di5cqVetu//vprXLlyBUFBQbptjY2N+P3vf49169bhhx9+MGjL3d0d7u7uBttlMpnNLnJbtu1oJJLmS9nVVcKYmYHXlvkYK/MxVpZhvMxnzVhZ0o7oSZKWQqGAQqHAtWvXkJGRgdWrV+vt9/HxAQDk5+fjxIkTWLVq1R3b3L59O+rq6vDcc8/pbZ82bRrUarXetpEjR2LatGmYOXPmPZ4JiYGf20ZERNYmepKUkZEBQRAQGhqKgoICLFq0CGFhYbpkZfv27VAqlQgKCkJubi4SEhIQFRWFyMhIXRuxsbEIDAxEamqqXtsbNmxAVFQU2rdvr7e9ffv2BttkMhn8/f0RGhpqozMlW9LeAoBv/yciImsRfUgpLy9HUlISiouL4evriwkTJiAlJUVXDistLUViYiLKysqgUqkQGxuL5ORkvTaKiooglerfzeD8+fPIzs7Gvn37Wu1cSDysJBERkbWJniRFR0cjOjra5P74+Pg7vgMtKyvLYFtoaCgsWZNubB0S3T9YSSIiImsT/Y7bRNbAShIREVkbkyRyCI2NEgBMkoiIyHqYJJFD0FaSON1GRETWwiSJHIJ2TRIrSUREZC1MksghsJJERETWxiSJHAIXbhMRkbUxSSKHwFsAEBGRtTFJIofAShIREVkbkyRyCKwkERGRtTFJIofAShIREVkbkyRyCLwFABERWRuTJHIIvAUAERFZG5MkcgisJBERkbUxSSKHwEoSERFZG5MkcghNTc3/spJERETWwiSJHAJvAUBERNbGJIkcQmOjBAArSUREZD1MksghsJJERETWxiSJHAJvJklERNbGJIkcAm8BQERE1sYkiRwCbwFARETWxiSJHAIrSUREZG1MksghsJJERETWxiSJHAIXbhMRkbUxSSKHwFsAEBGRtTFJIofAShIREVkbkyRyCFyTRERE1sYkiRwCK0lERGRtTJLIIfAWAEREZG1MksghcLqNiIisjUkSOQROtxERkbWJniRVVlZiwYIFCA4OhlwuR0REBI4fP67bX1ZWhhkzZiAgIACenp4YNWoU8vPzb9vm8OHDIZFIDL7Gjh0LANBoNPjjH/+I3r17Q6FQICAgALGxsbh06ZJNz5Vsp6FBAoCVJCIish7Rk6S4uDhkZmZi48aNyM3NRWRkJNRqNUpKSiAIAqKionDhwgXs3r0bp06dQnBwMNRqNaqqqky2uXPnTpSWluq+8vLy4OLigokTJwIAqqurcfLkSSQnJ+PkyZPYuXMnzp8/j6eeeqq1TpusjJUkIiKyNlH/7q6pqcGOHTuwe/duDBs2DACwfPlyfPLJJ0hLS0NsbCyOHDmCvLw8PPjggwCAtLQ0+Pv7Iz09HXFxcUbb9fX11Xu+detWeHp66pIkHx8fZGZm6h3z5ptvYtCgQSgqKkJQUJC1T5VsjDeTJCIiaxN1SGloaEBjYyM8PDz0tsvlcmRnZyMmJgYA9PZLpVK4u7sjOzvbZJJ0qw0bNmDSpElQKBQmjykvL4dEIkHbtm2N7q+rq0NdXZ3ueUVFBYDmqTuNRmNWP8ylbc/a7Tqim7FqQnNhtPF/j8kYXlvmY6zMx1hZhvEyny1iZUlbEkEQBKv95LsQEREBNzc3bNmyBR07dkR6ejqmT5+OkJAQ5OXlISQkBOHh4Vi/fj0UCgXWrl2LxYsXIzIyEhkZGXds/9ixYwgPD8fRo0cxaNAgo8fU1tZiyJAhCAsLw+bNm40es3z5cqxYscJg+5YtW+Dp6WnZSZPVrV49AIcOBeL5589i7NiLYneHiIjsVHV1NaZMmYLy8nJ4e3vf9ljRk6TCwkLMmjULBw8ehIuLC/r164cePXogJycH586dQ05ODmbPno0zZ87AxcUFarUaUqkUgiDgs88+u2P7v/3tb3H48GGcPXvW6H6NRoMJEyaguLgYWVlZJgNmrJLUuXNnXL169Y5BtpRGo0FmZiZGjBgBmUxm1bYdjTZW7703Frt3u+KNNxrx29+ykmQKry3zMVbmY6wsw3iZzxaxqqiogJ+fn1lJkugrOLp3744DBw6gqqoKFRUVUKlUiImJQbdu3QAA/fv3x+nTp1FeXo76+noolUqEh4djwIABd2y7qqoKW7duxcqVK43u12g0iI6Oxo8//oivvvrqtsFyd3eHu7u7wXaZTGazi9yWbTuaxsbm9yC4ublAJuPq7TvhtWU+xsp8jJVlGC/zWTNWlrQj+rvbtBQKBVQqFa5du4aMjAyMHz9eb7+Pjw+USiXy8/Nx4sQJg/3GbN++HXV1dXjuuecM9mkTpPz8fHzxxRdo37691c6FWl/T/4pHXLhNRETWIvqQkpGRAUEQEBoaioKCAixatAhhYWGYOXMmgOZER6lUIigoCLm5uUhISEBUVBQiIyN1bcTGxiIwMBCpqal6bW/YsAFRUVEGCZBGo8Gzzz6LkydP4tNPP0VjYyMuX74MoPmdcW5ubjY+a7I23gKAiIisTfQkqby8HElJSSguLoavry8mTJiAlJQUXTmstLQUiYmJKCsrg0qlQmxsLJKTk/XaKCoqglSqXxQ7f/48srOzsW/fPoOfWVJSgj179gAAfvOb3+jt279/P4YPH269E6RWwVsAEBGRtYk+pERHRyM6Otrk/vj4eMTHx9+2jaysLINtoaGhMLUmvUuXLib30f2JlSQiIrI2u1mTRHQvWEkiIiJrY5JEDoGVJCIisjYmSeQQtJUkJklERGQtTJLIIWgrSZxuIyIia2GSRA6hoUECgJUkIiKyHiZJ5BBYSSIiImtjkkQOgQu3iYjI2pgkkUPgLQCIiMjamCSRQ9B+dhsrSUREZC1MksghsJJERETWxiSJHALXJBERkbUxSSKHwJtJEhGRtTFJIofAWwAQEZG1MUkih8BKEhERWRuTJHIIrCQREZG1MUkih8CF20REZG1Mksgh8BYARERkbUySyCGwkkRERNbGJInue4IANDZKALCSRERE1sMkie572o8kAVhJIiIi62GSRPe9pqablzGTJCIishYmSXTfa2qS6B5zuo2IiKyFSRLd97TrkQBWkoiIyHqYJNF9j5UkIiKyBSZJdN9rmSSxkkRERNbCJInue9rpNokEkPKKJiIiK+GQQvc9bSWJVSQiIrImJkl03+ONJImIyBaYJNF9j5UkIiKyBSZJdN/TVpKYJBERkTUxSaL7nraSxOk2IiKyJtGTpMrKSixYsADBwcGQy+WIiIjA8ePHdfvLysowY8YMBAQEwNPTE6NGjUJ+fv5t2xw+fDgkEonB19ixY3XHCIKAV155BSqVCnK5HGq1+o7tkn1iJYmIiGxB9CQpLi4OmZmZ2LhxI3JzcxEZGQm1Wo2SkhIIgoCoqChcuHABu3fvxqlTpxAcHAy1Wo2qqiqTbe7cuROlpaW6r7y8PLi4uGDixIm6Y1avXo2///3veOedd3D06FEoFAqMHDkStbW1rXHaZEWsJBERkS2ImiTV1NRgx44dWL16NYYNG4aQkBAsX74cISEhSEtLQ35+Po4cOYK0tDQMHDgQoaGhSEtLQ01NDdLT00226+vrC39/f91XZmYmPD09dUmSIAhYt24dli5divHjx6NPnz744IMPcOnSJXz88cetdPZkLVy4TUREtiDq394NDQ1obGyEh4eH3na5XI7s7GzExMQAgN5+qVQKd3d3ZGdnIy4uzqyfs2HDBkyaNAkKhQIAcPHiRVy+fBlqtVp3jI+PD8LDw3H48GFMmjTJoI26ujrU1dXpnldUVAAANBoNNBqNmWdsHm171m7XEWk0GjQ1Nef6rq4CNJoGkXtk33htmY+xMh9jZRnGy3y2iJUlbYmaJHl5eWHw4MFYtWoVevbsiY4dOyI9PR2HDx9GSEgIwsLCEBQUhKSkJKxfvx4KhQJr165FcXExSktLzfoZx44dQ15eHjZs2KDbdvnyZQBAx44d9Y7t2LGjbt+tUlNTsWLFCoPt+/btg6enp7mnbJHMzEybtOtompraAQBqa6uwd++XIvfm/sBry3yMlfkYK8swXuazZqyqq6vNPlb0VRwbN27ErFmzEBgYCBcXF/Tr1w+TJ09GTk4OZDIZdu7cidmzZ8PX1xcuLi5Qq9UYPXo0BEEwq/0NGzagd+/eGDRo0D31MykpCYmJibrnFRUV6Ny5MyIjI+Ht7X1Pbd9Ko9EgMzMTI0aMgEwms2rbjkaj0eCbb04CALy9FRgzZozIPbJvvLbMx1iZj7GyDONlPlvESjsTZA7Rk6Tu3bvjwIEDqKqqQkVFBVQqFWJiYtCtWzcAQP/+/XH69GmUl5ejvr4eSqUS4eHhGDBgwB3brqqqwtatW7Fy5Uq97f7+/gCa3zmnUql028vKyvCb3/zGaFvu7u5wd3c32C6TyWx2kduybUdyc+G2hPEyE68t8zFW5mOsLMN4mc+asbKkHdHf3aalUCigUqlw7do1ZGRkYPz48Xr7fXx8oFQqkZ+fjxMnThjsN2b79u2oq6vDc889p7e9a9eu8Pf3x5df3pyaqaiowNGjRzF48GDrnBC1Gt4CgIiIbEH0SlJGRgYEQUBoaCgKCgqwaNEihIWFYebMmQCaEx2lUomgoCDk5uYiISEBUVFRiIyM1LURGxuLwMBApKam6rW9YcMGREVFoX379nrbJRIJFixYgFdffRUPPPAAunbtiuTkZAQEBCAqKsrm50zWxVsAEBGRLYg+rJSXlyMpKQnFxcXw9fXFhAkTkJKSoiuHlZaWIjExUTc1Fhsbi+TkZL02ioqKIJXqF8XOnz+P7Oxs7Nu3z+jP/cMf/oCqqirMmTMH169fx9ChQ/H5558bvNOO7B9vAUBERLYgepIUHR2N6Ohok/vj4+MRHx9/2zaysrIMtoWGht52cbdEIsHKlSsN1ivR/Uc73cZKEhERWZPdrEkiulusJBERkS0wSaL7HitJRERkC0yS6L7HShIREdkCkyS677GSREREtsAkie57rCQREZEtMEmi+x6TJCIisgUmSXTf480kiYjIFjis2JmqKqC0FLhyRY4ffwT4sT63p9EA5eXNn6nHShIREVkTkyQ788knwOTJMgCRdzyWAEAGoCcAJklERGRdTJLsjIsL4OEhoKmp6X8ftSIRu0t2rjlWnp5SPP00Y0VERNbDJMnOTJwIREU1YO/evRgzZozuM+zIOI2GsSIiItvgwm0iIiIiI5gkERERERnBJImIiIjICCZJREREREYwSSIiIiIygkkSERERkRFMkoiIiIiMYJJEREREZASTJCIiIiIjmCQRERERGcEkiYiIiMgIJklERERERjBJIiIiIjKCSRIRERGREa5id+B+JQgCAKCiosLqbWs0GlRXV6OiogIymczq7TsSxsoyjJf5GCvzMVaWYbzMZ4tYacdt7Th+O0yS7lJlZSUAoHPnziL3hIiIiCxVWVkJHx+f2x4jEcxJpchAU1MTLl26BC8vL0gkEqu2XVFRgc6dO+Onn36Ct7e3Vdt2NIyVZRgv8zFW5mOsLMN4mc8WsRIEAZWVlQgICIBUevtVR6wk3SWpVIpOnTrZ9Gd4e3vzBWQmxsoyjJf5GCvzMVaWYbzMZ+1Y3amCpMWF20RERERGMEkiIiIiMoJJkh1yd3fHsmXL4O7uLnZX7B5jZRnGy3yMlfkYK8swXuYTO1ZcuE1ERERkBCtJREREREYwSSIiIiIygkkSERERkRFMkoiIiIiMYJJkZ9566y106dIFHh4eCA8Px7Fjx8TukuiWL18OiUSi9xUWFqbbX1tbi3nz5qF9+/Zo06YNJkyYgLKyMhF73LoOHjyIcePGISAgABKJBB9//LHefkEQ8Morr0ClUkEul0OtViM/P1/vmF9//RVTp06Ft7c32rZti9mzZ+PGjRuteBat406xmjFjhsG1NmrUKL1jnCVWqampGDhwILy8vNChQwdERUXh/PnzeseY89orKirC2LFj4enpiQ4dOmDRokVoaGhozVNpFebEa/jw4QbX19y5c/WOcYZ4paWloU+fProbRA4ePBifffaZbr89XVdMkuzItm3bkJiYiGXLluHkyZPo27cvRo4ciStXrojdNdE9+OCDKC0t1X1lZ2fr9i1cuBCffPIJtm/fjgMHDuDSpUt45plnROxt66qqqkLfvn3x1ltvGd2/evVq/P3vf8c777yDo0ePQqFQYOTIkaitrdUdM3XqVHzzzTfIzMzEp59+ioMHD2LOnDmtdQqt5k6xAoBRo0bpXWvp6el6+50lVgcOHMC8efNw5MgRZGZmQqPRIDIyElVVVbpj7vTaa2xsxNixY1FfX49Dhw7h3//+N95//3288sorYpySTZkTLwB4/vnn9a6v1atX6/Y5S7w6deqE119/HTk5OThx4gQef/xxjB8/Ht988w0AO7uuBLIbgwYNEubNm6d73tjYKAQEBAipqaki9kp8y5YtE/r27Wt03/Xr1wWZTCZs375dt+3cuXMCAOHw4cOt1EP7AUDYtWuX7nlTU5Pg7+8v/PnPf9Ztu379uuDu7i6kp6cLgiAI3377rQBAOH78uO6Yzz77TJBIJEJJSUmr9b213RorQRCE6dOnC+PHjzf5Pc4aK0EQhCtXrggAhAMHDgiCYN5rb+/evYJUKhUuX76sOyYtLU3w9vYW6urqWvcEWtmt8RIEQXj00UeFhIQEk9/jzPFq166d8K9//cvuritWkuxEfX09cnJyoFarddukUinUajUOHz4sYs/sQ35+PgICAtCtWzdMnToVRUVFAICcnBxoNBq9uIWFhSEoKIhxA3Dx4kVcvnxZLz4+Pj4IDw/Xxefw4cNo27YtBgwYoDtGrVZDKpXi6NGjrd5nsWVlZaFDhw4IDQ3FCy+8gF9++UW3z5ljVV5eDgDw9fUFYN5r7/Dhw+jduzc6duyoO2bkyJGoqKjQVQ0c1a3x0tq8eTP8/Pzw0EMPISkpCdXV1bp9zhivxsZGbN26FVVVVRg8eLDdXVf8gFs7cfXqVTQ2Nur9pwNAx44d8d1334nUK/sQHh6O999/H6GhoSgtLcWKFSvwyCOPIC8vD5cvX4abmxvatm2r9z0dO3bE5cuXxemwHdHGwNh1pd13+fJldOjQQW+/q6srfH19nS6Go0aNwjPPPIOuXbuisLAQS5YswejRo3H48GG4uLg4bayampqwYMECDBkyBA899BAAmPXau3z5stFrT7vPURmLFwBMmTIFwcHBCAgIwNmzZ/HHP/4R58+fx86dOwE4V7xyc3MxePBg1NbWok2bNti1axd69eqF06dP29V1xSSJ7N7o0aN1j/v06YPw8HAEBwfjww8/hFwuF7Fn5GgmTZqke9y7d2/06dMH3bt3R1ZWFp544gkReyauefPmIS8vT28tIJlmKl4t16717t0bKpUKTzzxBAoLC9G9e/fW7qaoQkNDcfr0aZSXl+Ojjz7C9OnTceDAAbG7ZYDTbXbCz88PLi4uBiv4y8rK4O/vL1Kv7FPbtm3Ro0cPFBQUwN/fH/X19bh+/breMYxbM20Mbndd+fv7G7w5oKGhAb/++qvTx7Bbt27w8/NDQUEBAOeM1fz58/Hpp59i//796NSpk267Oa89f39/o9eedp8jMhUvY8LDwwFA7/pylni5ubkhJCQE/fv3R2pqKvr27Yu//e1vdnddMUmyE25ubujfvz++/PJL3bampiZ8+eWXGDx4sIg9sz83btxAYWEhVCoV+vfvD5lMphe38+fPo6ioiHED0LVrV/j7++vFp6KiAkePHtXFZ/Dgwbh+/TpycnJ0x3z11VdoamrS/RJ3VsXFxfjll1+gUqkAOFesBEHA/PnzsWvXLnz11Vfo2rWr3n5zXnuDBw9Gbm6uXmKZmZkJb29v9OrVq3VOpJXcKV7GnD59GgD0ri9nidetmpqaUFdXZ3/XlVWXgdM92bp1q+Du7i68//77wrfffivMmTNHaNu2rd4Kfmf0+9//XsjKyhIuXrwo/Pe//xXUarXg5+cnXLlyRRAEQZg7d64QFBQkfPXVV8KJEyeEwYMHC4MHDxa5162nsrJSOHXqlHDq1CkBgLBmzRrh1KlTwo8//igIgiC8/vrrQtu2bYXdu3cLZ8+eFcaPHy907dpVqKmp0bUxatQo4eGHHxaOHj0qZGdnCw888IAwefJksU7JZm4Xq8rKSuGll14SDh8+LFy8eFH44osvhH79+gkPPPCAUFtbq2vDWWL1wgsvCD4+PkJWVpZQWlqq+6qurtYdc6fXXkNDg/DQQw8JkZGRwunTp4XPP/9cUCqVQlJSkhinZFN3ildBQYGwcuVK4cSJE8LFixeF3bt3C926dROGDRuma8NZ4rV48WLhwIEDwsWLF4WzZ88KixcvFiQSibBv3z5BEOzrumKSZGfeeOMNISgoSHBzcxMGDRokHDlyROwuiS4mJkZQqVSCm5ubEBgYKMTExAgFBQW6/TU1NcKLL74otGvXTvD09BSefvppobS0VMQet679+/cLAAy+pk+fLghC820AkpOThY4dOwru7u7CE088IZw/f16vjV9++UWYPHmy0KZNG8Hb21uYOXOmUFlZKcLZ2NbtYlVdXS1ERkYKSqVSkMlkQnBwsPD8888b/JHiLLEyFicAwnvvvac7xpzX3g8//CCMHj1akMvlgp+fn/D73/9e0Gg0rXw2tneneBUVFQnDhg0TfH19BXd3dyEkJERYtGiRUF5erteOM8Rr1qxZQnBwsODm5iYolUrhiSee0CVIgmBf15VEEATBurUpIiIiovsf1yQRERERGcEkiYiIiMgIJklERERERjBJIiIiIjKCSRIRERGREUySiIiIiIxgkkRERERkBJMkIqJbSCQSfPzxx2J3g4hExiSJiBzKjBkzEBUVJXY3iMgBMEkiIiIiMoJJEhE5rOHDhyM+Ph5/+MMf4OvrC39/fyxfvlzvmPz8fAwbNgweHh7o1asXMjMzDdr56aefEB0djbZt28LX1xfjx4/HDz/8AAD47rvv4OnpiS1btuiO//DDDyGXy/Htt9/a8vSIyMaYJBGRQ/v3v/8NhUKBo0ePYvXq1Vi5cqUuEWpqasIzzzwDNzc3HD16FO+88w7++Mc/6n2/RqPByJEj4eXlha+//hr//e9/0aZNG4waNQr19fUICwvDX/7yF7z44osoKipCcXEx5s6diz/96U/o1auXGKdMRFbCD7glIocyY8YMXL9+HR9//DGGDx+OxsZGfP3117r9gwYNwuOPP47XX38d+/btw9ixY/Hjjz8iICAAAPD5559j9OjR2LVrF6KiorBp0ya8+uqrOHfuHCQSCQCgvr4ebdu2xccff4zIyEgAwJNPPomKigq4ubnBxcUFn3/+ue54Iro/uYrdASIiW+rTp4/ec5VKhStXrgAAzp07h86dO+sSJAAYPHiw3vFnzpxBQUEBvLy89LbX1taisLBQ9/zdd99Fjx49IJVK8c033zBBInIATJKIyKHJZDK95xKJBE1NTWZ//40bN9C/f39s3rzZYJ9SqdQ9PnPmDKqqqiCVSlFaWgqVSnX3nSYiu8AkiYicVs+ePfHTTz/pJTVHjhzRO6Zfv37Ytm0bOnToAG9vb6Pt/Prrr5gxYwZefvlllJaWYurUqTh58iTkcrnNz4GIbIcLt4nIaanVavTo0QPTp0/HmTNn8PXXX+Pll1/WO2bq1Knw8/PD+PHj8fXXX+PixYvIyspCfHw8iouLAQBz585F586dsXTpUqxZswaNjY146aWXxDglIrIiJklE5LSkUil27dqFmpoaDBo0CHFxcUhJSdE7xtPTEwcPHkRQUBCeeeYZ9OzZE7Nnz0ZtbS28vb3xwQcfYO/evdi4cSNcXV2hUCiwadMm/POf/8Rnn30m0pkRkTXw3W1ERERERrCSRERERGQEkyQiIiIiI5gkERERERnBJImIiIjICCZJREREREYwSSIiIiIygkkSERERkRFMkoiIiIiMYJJEREREZASTJCIiIiIjmCQRERERGcEkiYiIiMiI/wekVyY2wSCQQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "indices = np.arange(len(values))\n",
    "plt.plot(indices, values, color='blue')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Accuracy vs. Indices')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(stumps, num,x_test,y_test ):   \n",
    "    new_stumps=stumps[:num+1]\n",
    "    x_new=x_test.T\n",
    "    acc=[[0,0] for i in range(2) ]\n",
    "    acc={\"-1\":[0,0],\"1\":[0,0]}\n",
    "    for i in range(x_new.shape[0]):\n",
    "        acc[str(y_test[i])][1]+=1\n",
    "\n",
    "        if (prediction(new_stumps, x_new[i])==y_test[i]):\n",
    "            acc[str(y_test[i])][0]+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # cate=[-1,1]\n",
    "    cnt=0\n",
    "    tot=0\n",
    "    for i in acc:\n",
    "        t=acc[i]\n",
    "        tot+=((t[0]/t[1])*100)\n",
    "        print(i,\":\",(t[0]/t[1])*100,\"%\")\n",
    "        cnt+=1\n",
    "    # minimumm=min(minimumm,tot/2)\n",
    "\n",
    "    print(\"Total Accuracy\",tot/2,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 : 99.79591836734694 %\n",
      "1 : 99.64757709251101 %\n",
      "Total Accuracy 99.72174772992898 %\n"
     ]
    }
   ],
   "source": [
    "find_accuracy(stumps, max_num_tree,x_test,y_test)\n",
    "# find_accuracy(stumps, 299,x_test,y_test)s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(misclass_left_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0314467227910231"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*loss_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
